{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpyyovS-IK7q"
      },
      "source": [
        "# Decision Tree Classifier Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwuSLQ1AE8We"
      },
      "source": [
        "## 1. Tools and Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RC0jw1duExDq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from math import log2\n",
        "\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi1yIB32ICSo"
      },
      "source": [
        "## 2. Tree Node Class\n",
        "The `Node` class represents a single node in a decision tree structure. It is used to store information about a decision point (for internal nodes) or a predicted value (for leaf nodes).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TLMsIqjlH_Vy"
      },
      "outputs": [],
      "source": [
        "class Node:\n",
        "  def __init__(self, left=None, right=None, info_gain=None, feature_index=None, threshold=None, value=None):\n",
        "    self.left = left\n",
        "    self.right = right\n",
        "    self.info_gain = info_gain  # Information gain of split\n",
        "    self.feature_index = feature_index  # Index of feature to split on\n",
        "    self.threshold = threshold  # Threshold value to split on\n",
        "    self.value = value  # Predicted value if node is leaf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBlRRKkCITZD"
      },
      "source": [
        "## 3. Decision Tree Class\n",
        "The `DecisionTreeClassifier` class implements a basic decision tree classifier. It recursively splits the feature space based on information gain, building a binary tree structure to classify data points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VAi-sSWUH6Rx"
      },
      "outputs": [],
      "source": [
        "class DecisionTreeClassifier:\n",
        "    def __init__(self, max_depth=7, min_samples_split=10):\n",
        "        \"\"\"Initialize the decision tree with hyperparameters.\"\"\"\n",
        "        self.max_depth = max_depth  # Maximum depth of the tree\n",
        "        self.min_samples_split = min_samples_split  # Minimum samples required to split a node\n",
        "        self.root = None  # Root node of the tree, starts as None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Train the decision tree using the input features X and target y.\"\"\"\n",
        "        self.root = self.build_tree(X, y)  # Build the tree and set the root\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Make predictions for each sample in X.\"\"\"\n",
        "        if self.root is None:\n",
        "            raise ValueError(\"Model has not been trained. Please call 'fit' method first.\")\n",
        "        # Return predictions by traversing the tree for each sample\n",
        "        return [self.make_prediction(x, self.root) for x in X]\n",
        "\n",
        "    def make_prediction(self, x, node):\n",
        "        \"\"\"Recursively traverse the tree to make a prediction for a single sample.\"\"\"\n",
        "        if node.value is not None:  # Leaf node reached\n",
        "            return node.value\n",
        "        # Decide which subtree to follow based on the feature value\n",
        "        if x[node.feature_index] <= node.threshold:\n",
        "            return self.make_prediction(x, node.left)\n",
        "        else:\n",
        "            return self.make_prediction(x, node.right)\n",
        "\n",
        "    def print_tree(self, feature_names):\n",
        "        \"\"\"Print the structure of the decision tree.\"\"\"\n",
        "        self.print_tree_helper(self.root, 0, feature_names)  # Start from the root with depth 0\n",
        "\n",
        "    def print_tree_helper(self, node, depth, feature_names):\n",
        "        \"\"\"Helper method to recursively print the tree with indentation.\"\"\"\n",
        "        if node is None:\n",
        "            return\n",
        "        indent = \" \" * depth  # Indentation for visual hierarchy\n",
        "        if node.value is not None:  # Leaf node\n",
        "            print(f\"{indent}Predict: {node.value}\")\n",
        "        else:  # Internal node\n",
        "            print(f\"{indent}{feature_names[node.feature_index]} <= {node.threshold} -> True:\")\n",
        "            self.print_tree_helper(node.left, depth + 1, feature_names)\n",
        "            print(f\"{indent}{feature_names[node.feature_index]} > {node.threshold} -> False:\")\n",
        "            self.print_tree_helper(node.right, depth + 1, feature_names)\n",
        "\n",
        "    def build_tree(self, X, y, depth=0):\n",
        "        \"\"\"Recursively build the decision tree.\"\"\"\n",
        "        m, n = X.shape  # Number of samples (m) and features (n)\n",
        "        is_pure = len(np.unique(y)) == 1  # Check if all labels are the same\n",
        "\n",
        "        # Base case: stop if max depth reached, data is pure, or too few samples\n",
        "        if depth >= self.max_depth or is_pure or m < self.min_samples_split:\n",
        "            majority_class = self.compute_output(y)  # Assign majority class to leaf\n",
        "            return Node(value=majority_class)\n",
        "\n",
        "        # Find the best split and recursively build left and right subtrees\n",
        "        best_split = self.get_best_split(X, y)\n",
        "        left_indices = best_split['left']\n",
        "        right_indices = best_split['right']\n",
        "        left_subtree = self.build_tree(X[left_indices, :], y[left_indices], depth + 1)\n",
        "        right_subtree = self.build_tree(X[right_indices, :], y[right_indices], depth + 1)\n",
        "\n",
        "        # Return a node with the split details and subtrees\n",
        "        return Node(left=left_subtree,\n",
        "                    right=right_subtree,\n",
        "                    info_gain=best_split['info_gain'],\n",
        "                    feature_index=best_split['feature_index'],\n",
        "                    threshold=best_split['threshold'])\n",
        "\n",
        "    def get_best_split(self, X, y):\n",
        "        \"\"\"Find the best feature and threshold to split the data.\"\"\"\n",
        "        _, n = X.shape\n",
        "        best_split = {\n",
        "            'info_gain': float('-inf'),\n",
        "            'threshold': None,\n",
        "            'feature_index': None,\n",
        "            'left': None,\n",
        "            'right': None\n",
        "        }\n",
        "\n",
        "        # Iterate over all features and their unique values as potential thresholds\n",
        "        for feature_index in range(n):\n",
        "            feature_values = X[:, feature_index]\n",
        "            possible_thresholds = np.unique(feature_values)\n",
        "            for threshold in possible_thresholds:\n",
        "                # Split data based on the threshold\n",
        "                left_indices = X[:, feature_index] <= threshold\n",
        "                right_indices = X[:, feature_index] > threshold\n",
        "                left_y = y[left_indices]\n",
        "                right_y = y[right_indices]\n",
        "\n",
        "                if len(left_y) == 0 or len(right_y) == 0:\n",
        "                    continue\n",
        "                \n",
        "                # Calculate information gain for this split\n",
        "                split_info_gain = self.compute_information_gain(y, left_y, right_y)\n",
        "\n",
        "                # Update best split if this one is better\n",
        "                if split_info_gain > best_split['info_gain']:\n",
        "                    best_split['info_gain'] = split_info_gain\n",
        "                    best_split['feature_index'] = feature_index\n",
        "                    best_split['threshold'] = threshold\n",
        "                    best_split['left'] = left_indices\n",
        "                    best_split['right'] = right_indices\n",
        "\n",
        "        return best_split\n",
        "\n",
        "    def compute_output(self, y):\n",
        "        \"\"\"Compute the majority class for a leaf node.\"\"\"\n",
        "        unique_classes, frequency = np.unique(y, return_counts=True)\n",
        "        majority_class = unique_classes[np.argmax(frequency)]  # Most frequent class\n",
        "        # majority_count = frequency.max()\n",
        "        # print(f\"\\nMajority Class: {majority_class} (Count: {majority_count})\")\n",
        "        return int(majority_class)\n",
        "\n",
        "    def compute_entropy(self, y):\n",
        "        \"\"\"Calculate the entropy of a set of labels.\"\"\"\n",
        "        unique_classes, frequencies = np.unique(y, return_counts=True)\n",
        "        n_classes = len(y)\n",
        "        entropy = 0\n",
        "        for frequency in frequencies:\n",
        "            probability = frequency / n_classes\n",
        "            entropy -= probability * log2(probability) if probability > 0 else 0\n",
        "        return entropy\n",
        "\n",
        "    def compute_information_gain(self, y, left_y, right_y):\n",
        "        \"\"\"Calculate information gain from a split.\"\"\"\n",
        "        m = len(y)\n",
        "        left_m = len(left_y)\n",
        "        right_m = len(right_y)\n",
        "\n",
        "        # Entropy before and after the split\n",
        "        parent_entropy = self.compute_entropy(y)\n",
        "        left_entropy = self.compute_entropy(left_y) if left_m > 0 else 0\n",
        "        right_entropy = self.compute_entropy(right_y) if right_m > 0 else 0\n",
        "\n",
        "        # Weighted average of child entropies\n",
        "        weighted_entropy = (left_m / m) * left_entropy + (right_m / m) * right_entropy\n",
        "        information_gain = parent_entropy - weighted_entropy\n",
        "        return information_gain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Loading and Preprocessing the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>RestingBP</th>\n",
              "      <th>Cholesterol</th>\n",
              "      <th>FastingBS</th>\n",
              "      <th>MaxHR</th>\n",
              "      <th>Oldpeak</th>\n",
              "      <th>HeartDisease</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>918.000000</td>\n",
              "      <td>918.000000</td>\n",
              "      <td>918.000000</td>\n",
              "      <td>918.000000</td>\n",
              "      <td>918.000000</td>\n",
              "      <td>918.000000</td>\n",
              "      <td>918.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>53.510893</td>\n",
              "      <td>132.396514</td>\n",
              "      <td>198.799564</td>\n",
              "      <td>0.233115</td>\n",
              "      <td>136.809368</td>\n",
              "      <td>0.887364</td>\n",
              "      <td>0.553377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>9.432617</td>\n",
              "      <td>18.514154</td>\n",
              "      <td>109.384145</td>\n",
              "      <td>0.423046</td>\n",
              "      <td>25.460334</td>\n",
              "      <td>1.066570</td>\n",
              "      <td>0.497414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>-2.600000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>47.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>173.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>54.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>223.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>138.000000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>60.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>267.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>156.000000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>77.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>603.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>202.000000</td>\n",
              "      <td>6.200000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Age   RestingBP  Cholesterol   FastingBS       MaxHR  \\\n",
              "count  918.000000  918.000000   918.000000  918.000000  918.000000   \n",
              "mean    53.510893  132.396514   198.799564    0.233115  136.809368   \n",
              "std      9.432617   18.514154   109.384145    0.423046   25.460334   \n",
              "min     28.000000    0.000000     0.000000    0.000000   60.000000   \n",
              "25%     47.000000  120.000000   173.250000    0.000000  120.000000   \n",
              "50%     54.000000  130.000000   223.000000    0.000000  138.000000   \n",
              "75%     60.000000  140.000000   267.000000    0.000000  156.000000   \n",
              "max     77.000000  200.000000   603.000000    1.000000  202.000000   \n",
              "\n",
              "          Oldpeak  HeartDisease  \n",
              "count  918.000000    918.000000  \n",
              "mean     0.887364      0.553377  \n",
              "std      1.066570      0.497414  \n",
              "min     -2.600000      0.000000  \n",
              "25%      0.000000      0.000000  \n",
              "50%      0.600000      1.000000  \n",
              "75%      1.500000      1.000000  \n",
              "max      6.200000      1.000000  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the dataset\n",
        "heart_df = pd.read_csv('heart.csv')\n",
        "heart_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>RestingBP</th>\n",
              "      <th>Cholesterol</th>\n",
              "      <th>FastingBS</th>\n",
              "      <th>MaxHR</th>\n",
              "      <th>Oldpeak</th>\n",
              "      <th>HeartDisease</th>\n",
              "      <th>Sex_M</th>\n",
              "      <th>ChestPainType_ATA</th>\n",
              "      <th>ChestPainType_NAP</th>\n",
              "      <th>ChestPainType_TA</th>\n",
              "      <th>RestingECG_Normal</th>\n",
              "      <th>RestingECG_ST</th>\n",
              "      <th>ExerciseAngina_Y</th>\n",
              "      <th>ST_Slope_Flat</th>\n",
              "      <th>ST_Slope_Up</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>918.000000</td>\n",
              "      <td>918.000000</td>\n",
              "      <td>918.000000</td>\n",
              "      <td>918.000000</td>\n",
              "      <td>918.000000</td>\n",
              "      <td>918.000000</td>\n",
              "      <td>918.000000</td>\n",
              "      <td>918.000000</td>\n",
              "      <td>918.000000</td>\n",
              "      <td>918.000000</td>\n",
              "      <td>918.000000</td>\n",
              "      <td>918.000000</td>\n",
              "      <td>918.000000</td>\n",
              "      <td>918.000000</td>\n",
              "      <td>918.000000</td>\n",
              "      <td>918.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>53.510893</td>\n",
              "      <td>132.396514</td>\n",
              "      <td>198.799564</td>\n",
              "      <td>0.233115</td>\n",
              "      <td>136.809368</td>\n",
              "      <td>0.887364</td>\n",
              "      <td>0.553377</td>\n",
              "      <td>0.789760</td>\n",
              "      <td>0.188453</td>\n",
              "      <td>0.221133</td>\n",
              "      <td>0.050109</td>\n",
              "      <td>0.601307</td>\n",
              "      <td>0.193900</td>\n",
              "      <td>0.404139</td>\n",
              "      <td>0.501089</td>\n",
              "      <td>0.430283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>9.432617</td>\n",
              "      <td>18.514154</td>\n",
              "      <td>109.384145</td>\n",
              "      <td>0.423046</td>\n",
              "      <td>25.460334</td>\n",
              "      <td>1.066570</td>\n",
              "      <td>0.497414</td>\n",
              "      <td>0.407701</td>\n",
              "      <td>0.391287</td>\n",
              "      <td>0.415236</td>\n",
              "      <td>0.218289</td>\n",
              "      <td>0.489896</td>\n",
              "      <td>0.395567</td>\n",
              "      <td>0.490992</td>\n",
              "      <td>0.500271</td>\n",
              "      <td>0.495386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>-2.600000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>47.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>173.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>54.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>223.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>138.000000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>60.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>267.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>156.000000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>77.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>603.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>202.000000</td>\n",
              "      <td>6.200000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Age   RestingBP  Cholesterol   FastingBS       MaxHR  \\\n",
              "count  918.000000  918.000000   918.000000  918.000000  918.000000   \n",
              "mean    53.510893  132.396514   198.799564    0.233115  136.809368   \n",
              "std      9.432617   18.514154   109.384145    0.423046   25.460334   \n",
              "min     28.000000    0.000000     0.000000    0.000000   60.000000   \n",
              "25%     47.000000  120.000000   173.250000    0.000000  120.000000   \n",
              "50%     54.000000  130.000000   223.000000    0.000000  138.000000   \n",
              "75%     60.000000  140.000000   267.000000    0.000000  156.000000   \n",
              "max     77.000000  200.000000   603.000000    1.000000  202.000000   \n",
              "\n",
              "          Oldpeak  HeartDisease       Sex_M  ChestPainType_ATA  \\\n",
              "count  918.000000    918.000000  918.000000         918.000000   \n",
              "mean     0.887364      0.553377    0.789760           0.188453   \n",
              "std      1.066570      0.497414    0.407701           0.391287   \n",
              "min     -2.600000      0.000000    0.000000           0.000000   \n",
              "25%      0.000000      0.000000    1.000000           0.000000   \n",
              "50%      0.600000      1.000000    1.000000           0.000000   \n",
              "75%      1.500000      1.000000    1.000000           0.000000   \n",
              "max      6.200000      1.000000    1.000000           1.000000   \n",
              "\n",
              "       ChestPainType_NAP  ChestPainType_TA  RestingECG_Normal  RestingECG_ST  \\\n",
              "count         918.000000        918.000000         918.000000     918.000000   \n",
              "mean            0.221133          0.050109           0.601307       0.193900   \n",
              "std             0.415236          0.218289           0.489896       0.395567   \n",
              "min             0.000000          0.000000           0.000000       0.000000   \n",
              "25%             0.000000          0.000000           0.000000       0.000000   \n",
              "50%             0.000000          0.000000           1.000000       0.000000   \n",
              "75%             0.000000          0.000000           1.000000       0.000000   \n",
              "max             1.000000          1.000000           1.000000       1.000000   \n",
              "\n",
              "       ExerciseAngina_Y  ST_Slope_Flat  ST_Slope_Up  \n",
              "count        918.000000     918.000000   918.000000  \n",
              "mean           0.404139       0.501089     0.430283  \n",
              "std            0.490992       0.500271     0.495386  \n",
              "min            0.000000       0.000000     0.000000  \n",
              "25%            0.000000       0.000000     0.000000  \n",
              "50%            0.000000       1.000000     0.000000  \n",
              "75%            1.000000       1.000000     1.000000  \n",
              "max            1.000000       1.000000     1.000000  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Encode categorical features using One-Hot Encoding\n",
        "categorical_features = ['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope']\n",
        "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
        "encoded_features = encoder.fit_transform(heart_df[categorical_features])\n",
        "encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(categorical_features))\n",
        "modified_df = pd.concat([heart_df.drop(categorical_features, axis=1), encoded_df], axis=1)\n",
        "\n",
        "modified_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the dataset into training, validation, and test sets\n",
        "X = modified_df.drop('HeartDisease', axis=1)\n",
        "y = modified_df['HeartDisease']\n",
        "\n",
        "# Split the dataset into training, validation (80%) and test (20%) sets, maintaining class distribution\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Split the training set into training (70%) and validation (10%) sets, maintaining class distribution\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.125, random_state=42, stratify=y_temp)\n",
        "\n",
        "# Convert to NumPy arrays\n",
        "X_train = X_train.to_numpy()\n",
        "X_val = X_val.to_numpy()\n",
        "X_test = X_test.to_numpy()\n",
        "y_train = y_train.to_numpy()\n",
        "y_val = y_val.to_numpy()\n",
        "y_test = y_test.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Training the Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize and train the Decision Tree Classifier\n",
        "decision_tree_classifier = DecisionTreeClassifier()\n",
        "decision_tree_classifier.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Hyperparameter Tuning\n",
        "We will tune the hyperparameters `max_depth` and `min_samples_split` using the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(cm):\n",
        "    \"\"\"Plot the confusion matrix.\"\"\"\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(cm, cmap='Blues', interpolation='nearest')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.colorbar(label='Count')\n",
        "    plt.xticks([0, 1], ['Predicted 0', 'Predicted 1'])\n",
        "    plt.yticks([0, 1], ['True 0', 'True 1'])\n",
        "    for i in range(2):\n",
        "        for j in range(2):\n",
        "            plt.text(j, i, cm[i, j], ha='center', va='center', color='black')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Misclassification Rate (Depth=2, MinSamplesSplit=2): 0.20652173913043478\n",
            "Misclassification Rate (Depth=2, MinSamplesSplit=5): 0.20652173913043478\n",
            "Misclassification Rate (Depth=2, MinSamplesSplit=10): 0.20652173913043478\n",
            "Misclassification Rate (Depth=2, MinSamplesSplit=15): 0.20652173913043478\n",
            "Misclassification Rate (Depth=2, MinSamplesSplit=20): 0.20652173913043478\n",
            "Misclassification Rate (Depth=2, MinSamplesSplit=25): 0.20652173913043478\n",
            "Misclassification Rate (Depth=2, MinSamplesSplit=30): 0.20652173913043478\n",
            "\n",
            "Misclassification Rate (Depth=3, MinSamplesSplit=2): 0.18478260869565216\n",
            "Misclassification Rate (Depth=3, MinSamplesSplit=5): 0.18478260869565216\n",
            "Misclassification Rate (Depth=3, MinSamplesSplit=10): 0.18478260869565216\n",
            "Misclassification Rate (Depth=3, MinSamplesSplit=15): 0.18478260869565216\n",
            "Misclassification Rate (Depth=3, MinSamplesSplit=20): 0.18478260869565216\n",
            "Misclassification Rate (Depth=3, MinSamplesSplit=25): 0.18478260869565216\n",
            "Misclassification Rate (Depth=3, MinSamplesSplit=30): 0.18478260869565216\n",
            "\n",
            "Misclassification Rate (Depth=5, MinSamplesSplit=2): 0.20652173913043478\n",
            "Misclassification Rate (Depth=5, MinSamplesSplit=5): 0.20652173913043478\n",
            "Misclassification Rate (Depth=5, MinSamplesSplit=10): 0.20652173913043478\n",
            "Misclassification Rate (Depth=5, MinSamplesSplit=15): 0.20652173913043478\n",
            "Misclassification Rate (Depth=5, MinSamplesSplit=20): 0.20652173913043478\n",
            "Misclassification Rate (Depth=5, MinSamplesSplit=25): 0.20652173913043478\n",
            "Misclassification Rate (Depth=5, MinSamplesSplit=30): 0.20652173913043478\n",
            "\n",
            "Misclassification Rate (Depth=7, MinSamplesSplit=2): 0.21739130434782608\n",
            "Misclassification Rate (Depth=7, MinSamplesSplit=5): 0.21739130434782608\n",
            "Misclassification Rate (Depth=7, MinSamplesSplit=10): 0.21739130434782608\n",
            "Misclassification Rate (Depth=7, MinSamplesSplit=15): 0.21739130434782608\n",
            "Misclassification Rate (Depth=7, MinSamplesSplit=20): 0.2391304347826087\n",
            "Misclassification Rate (Depth=7, MinSamplesSplit=25): 0.22826086956521738\n",
            "Misclassification Rate (Depth=7, MinSamplesSplit=30): 0.22826086956521738\n",
            "\n",
            "Misclassification Rate (Depth=9, MinSamplesSplit=2): 0.21739130434782608\n",
            "Misclassification Rate (Depth=9, MinSamplesSplit=5): 0.20652173913043478\n",
            "Misclassification Rate (Depth=9, MinSamplesSplit=10): 0.21739130434782608\n",
            "Misclassification Rate (Depth=9, MinSamplesSplit=15): 0.20652173913043478\n",
            "Misclassification Rate (Depth=9, MinSamplesSplit=20): 0.22826086956521738\n",
            "Misclassification Rate (Depth=9, MinSamplesSplit=25): 0.21739130434782608\n",
            "Misclassification Rate (Depth=9, MinSamplesSplit=30): 0.21739130434782608\n",
            "\n",
            "Misclassification Rate (Depth=11, MinSamplesSplit=2): 0.22826086956521738\n",
            "Misclassification Rate (Depth=11, MinSamplesSplit=5): 0.21739130434782608\n",
            "Misclassification Rate (Depth=11, MinSamplesSplit=10): 0.21739130434782608\n",
            "Misclassification Rate (Depth=11, MinSamplesSplit=15): 0.20652173913043478\n",
            "Misclassification Rate (Depth=11, MinSamplesSplit=20): 0.22826086956521738\n",
            "Misclassification Rate (Depth=11, MinSamplesSplit=25): 0.21739130434782608\n",
            "Misclassification Rate (Depth=11, MinSamplesSplit=30): 0.21739130434782608\n",
            "\n",
            "Misclassification Rate (Depth=13, MinSamplesSplit=2): 0.22826086956521738\n",
            "Misclassification Rate (Depth=13, MinSamplesSplit=5): 0.21739130434782608\n",
            "Misclassification Rate (Depth=13, MinSamplesSplit=10): 0.21739130434782608\n",
            "Misclassification Rate (Depth=13, MinSamplesSplit=15): 0.20652173913043478\n",
            "Misclassification Rate (Depth=13, MinSamplesSplit=20): 0.22826086956521738\n",
            "Misclassification Rate (Depth=13, MinSamplesSplit=25): 0.21739130434782608\n",
            "Misclassification Rate (Depth=13, MinSamplesSplit=30): 0.21739130434782608\n",
            "\n",
            "Misclassification Rate (Depth=15, MinSamplesSplit=2): 0.22826086956521738\n",
            "Misclassification Rate (Depth=15, MinSamplesSplit=5): 0.21739130434782608\n",
            "Misclassification Rate (Depth=15, MinSamplesSplit=10): 0.21739130434782608\n",
            "Misclassification Rate (Depth=15, MinSamplesSplit=15): 0.20652173913043478\n",
            "Misclassification Rate (Depth=15, MinSamplesSplit=20): 0.22826086956521738\n",
            "Misclassification Rate (Depth=15, MinSamplesSplit=25): 0.21739130434782608\n",
            "Misclassification Rate (Depth=15, MinSamplesSplit=30): 0.21739130434782608\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Tune hyperparameters\n",
        "max_depth_values = [2, 3, 5, 7, 9, 11, 13, 15]\n",
        "min_samples_split_values = [2, 5, 10, 15, 20, 25, 30]\n",
        "misclassification_rates = np.zeros((len(max_depth_values), len(min_samples_split_values)))\n",
        "\n",
        "for i, max_depth in enumerate(max_depth_values):\n",
        "    for j, min_samples_split in enumerate(min_samples_split_values):\n",
        "        decision_tree_classifier = DecisionTreeClassifier(max_depth=max_depth, min_samples_split=min_samples_split)\n",
        "        decision_tree_classifier.fit(X_train, y_train)\n",
        "        y_pred = decision_tree_classifier.predict(X_val)\n",
        "        # cm = confusion_matrix(y_val, y_pred)\n",
        "        # plot_confusion_matrix(cm)\n",
        "        misclassification_rates[i, j] = np.mean(y_pred != y_val)\n",
        "        print(f\"Misclassification Rate (Depth={max_depth}, MinSamplesSplit={min_samples_split}): {misclassification_rates[i, j]}\")\n",
        "    print(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Max Depth: 3\n",
            "Best Min Samples Split: 2\n",
            "Misclassification Rate: 0.24456521739130435\n",
            "Accuracy: 0.7554347826086957\n",
            "F1-Score: 0.789\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ST_Slope_Up <= 0.0 -> True:\n",
            " MaxHR <= 142.0 -> True:\n",
            "  Sex_M <= 0.0 -> True:\n",
            "   Predict: 1\n",
            "  Sex_M > 0.0 -> False:\n",
            "   Predict: 1\n",
            " MaxHR > 142.0 -> False:\n",
            "  Cholesterol <= 190.0 -> True:\n",
            "   Predict: 1\n",
            "  Cholesterol > 190.0 -> False:\n",
            "   Predict: 1\n",
            "ST_Slope_Up > 0.0 -> False:\n",
            " Oldpeak <= 0.4 -> True:\n",
            "  Age <= 55.0 -> True:\n",
            "   Predict: 0\n",
            "  Age > 55.0 -> False:\n",
            "   Predict: 0\n",
            " Oldpeak > 0.4 -> False:\n",
            "  MaxHR <= 132.0 -> True:\n",
            "   Predict: 1\n",
            "  MaxHR > 132.0 -> False:\n",
            "   Predict: 0\n"
          ]
        }
      ],
      "source": [
        "# Find the best hyperparameters\n",
        "best_idx = np.unravel_index(np.argmin(misclassification_rates, axis=None), misclassification_rates.shape)\n",
        "best_max_depth = max_depth_values[best_idx[0]]\n",
        "best_min_samples_split = min_samples_split_values[best_idx[1]]\n",
        "print(f\"Best Max Depth: {best_max_depth}\")\n",
        "print(f\"Best Min Samples Split: {best_min_samples_split}\")\n",
        "\n",
        "# Intialize and train the Decision Tree Classifier with the best hyperparameters\n",
        "decision_tree_classifier = DecisionTreeClassifier(max_depth=best_max_depth, min_samples_split=best_min_samples_split)\n",
        "decision_tree_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions and evaluate the model on the test set\n",
        "y_pred = decision_tree_classifier.predict(X_test)\n",
        "\n",
        "# Calculate the misclassification rate, accuracy, F1-score, and confusion matrix\n",
        "misclassification_rate = np.mean(y_pred != y_test)\n",
        "print(f\"Misclassification Rate: {misclassification_rate}\")\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(f\"F1-Score: {f1:.3f}\")\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plot_confusion_matrix(cm)\n",
        "\n",
        "# Print the structure of the decision tree\n",
        "decision_tree_classifier.print_tree(feature_names=X.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
