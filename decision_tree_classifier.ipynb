{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpyyovS-IK7q"
      },
      "source": [
        "# Decision Tree Classifier Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwOq4-9gNGtq"
      },
      "source": [
        "This is an implementation of Decision Tree Classifier from scratch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwuSLQ1AE8We"
      },
      "source": [
        "## Tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RC0jw1duExDq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from math import log2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zi1yIB32ICSo"
      },
      "source": [
        "## Tree Node Class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TLMsIqjlH_Vy"
      },
      "outputs": [],
      "source": [
        "class Node:\n",
        "  def __init__(self, left=None, right=None, info_gain=None, feature_index=None, threshold=None, value=None):\n",
        "    self.left = left\n",
        "    self.right = right\n",
        "    self.info_gain = info_gain\n",
        "    self.feature_index = feature_index\n",
        "    self.threshold = threshold\n",
        "    self.value = value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPs_mwBNNxJr"
      },
      "source": [
        "The `Node` class represents a single node in a decision tree structure. It is used to store information about a decision point (for internal nodes) or a predicted value (for leaf nodes). This class is typically part of a decision tree implementation for machine learning tasks such as classification or regression.\n",
        "\n",
        "### Parameters\n",
        "- **left** (*Node, optional*): The left child node of the current node. Defaults to `None`. Used in internal nodes to reference the subtree for cases where the feature value is less than or equal to the threshold.\n",
        "- **right** (*Node, optional*): The right child node of the current node. Defaults to `None`. Used in internal nodes to reference the subtree for cases where the feature value exceeds the threshold.\n",
        "- **info_gain** (*float, optional*): The information gain achieved by splitting the data at this node. Defaults to `None`. Typically used in internal nodes to quantify the quality of the split.\n",
        "- **feature_index** (*int or str, optional*): The index of the feature used for splitting the data at this node. Defaults to `None`. Only applicable to internal nodes.\n",
        "- **threshold** (*float, optional*): The threshold value for the feature used to split the data. Defaults to `None`. Only applicable to internal nodes.\n",
        "- **value** (*any, optional*): The predicted value or class label stored in the node. Defaults to `None`. Typically used in leaf nodes to represent the output of the decision tree.\n",
        "\n",
        "### Usage\n",
        "This class is designed to be used as a building block for constructing a decision tree. Internal nodes will have `feature`, `threshold`, and `info_gain` defined, along with `left` and `right` child nodes. Leaf nodes will have a `value` defined but no children or split criteria."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBlRRKkCITZD"
      },
      "source": [
        "## Decision Tree Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VAi-sSWUH6Rx"
      },
      "outputs": [],
      "source": [
        "class DecisionTreeClassifier:\n",
        "    def __init__(self, max_depth=7, min_samples_split=10):\n",
        "        \"\"\"Initialize the decision tree with hyperparameters.\"\"\"\n",
        "        self.max_depth = max_depth  # Maximum depth of the tree\n",
        "        self.min_samples_split = min_samples_split  # Minimum samples required to split a node\n",
        "        self.root = None  # Root node of the tree, starts as None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Train the decision tree using the input features X and target y.\"\"\"\n",
        "        self.root = self.build_tree(X, y)  # Build the tree and set the root\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Make predictions for each sample in X.\"\"\"\n",
        "        if self.root is None:\n",
        "            raise ValueError(\"Model has not been trained. Please call 'fit' method first.\")\n",
        "        # Return predictions by traversing the tree for each sample\n",
        "        return [self.make_prediction(x, self.root) for x in X]\n",
        "\n",
        "    def make_prediction(self, x, node):\n",
        "        \"\"\"Recursively traverse the tree to make a prediction for a single sample.\"\"\"\n",
        "        if node.value is not None:  # Leaf node reached\n",
        "            return node.value\n",
        "        # Decide which subtree to follow based on the feature value\n",
        "        if x[node.feature_index] <= node.threshold:\n",
        "            return self.make_prediction(x, node.left)\n",
        "        else:\n",
        "            return self.make_prediction(x, node.right)\n",
        "\n",
        "    def print_tree(self):\n",
        "        \"\"\"Print the structure of the decision tree.\"\"\"\n",
        "        self.print_tree_helper(self.root, 0)  # Start from the root with depth 0\n",
        "\n",
        "    def print_tree_helper(self, node, depth):\n",
        "        \"\"\"Helper method to recursively print the tree with indentation.\"\"\"\n",
        "        if node is None:\n",
        "            return\n",
        "        indent = \" \" * depth  # Indentation for visual hierarchy\n",
        "        if node.value is not None:  # Leaf node\n",
        "            print(f\"{indent}Predict: {node.value}\")\n",
        "        else:  # Internal node\n",
        "            print(f\"{indent}X[{node.feature_index}] <= {node.threshold} -> True:\")\n",
        "            self.print_tree_helper(node.left, depth + 1)\n",
        "            print(f\"{indent}X[{node.feature_index}] > {node.threshold} -> False:\")\n",
        "            self.print_tree_helper(node.right, depth + 1)\n",
        "\n",
        "    def build_tree(self, X, y, depth=0):\n",
        "        \"\"\"Recursively build the decision tree.\"\"\"\n",
        "        m, n = X.shape  # Number of samples (m) and features (n)\n",
        "        is_pure = len(np.unique(y)) == 1  # Check if all labels are the same\n",
        "\n",
        "        # Base case: stop if max depth reached, data is pure, or too few samples\n",
        "        if depth >= self.max_depth or is_pure or m < self.min_samples_split:\n",
        "            majority_class = self.compute_output(y)  # Assign majority class to leaf\n",
        "            return Node(value=majority_class)\n",
        "\n",
        "        # Find the best split and recursively build left and right subtrees\n",
        "        best_split = self.get_best_split(X, y)\n",
        "        left_indices = best_split['left']\n",
        "        right_indices = best_split['right']\n",
        "        left_subtree = self.build_tree(X[left_indices, :], y[left_indices], depth + 1)\n",
        "        right_subtree = self.build_tree(X[right_indices, :], y[right_indices], depth + 1)\n",
        "\n",
        "        # Return a node with the split details and subtrees\n",
        "        return Node(left=left_subtree,\n",
        "                    right=right_subtree,\n",
        "                    info_gain=best_split['info_gain'],\n",
        "                    feature_index=best_split['feature_index'],\n",
        "                    threshold=best_split['threshold'])\n",
        "\n",
        "    def get_best_split(self, X, y):\n",
        "        \"\"\"Find the best feature and threshold to split the data.\"\"\"\n",
        "        _, n = X.shape\n",
        "        best_split = {\n",
        "            'info_gain': float('-inf'),\n",
        "            'threshold': None,\n",
        "            'feature_index': None,\n",
        "            'left': None,\n",
        "            'right': None\n",
        "        }\n",
        "\n",
        "        # Iterate over all features and their unique values as potential thresholds\n",
        "        for feature_index in range(n):\n",
        "            feature_values = X[:, feature_index]\n",
        "            possible_thresholds = np.unique(feature_values)\n",
        "            for threshold in possible_thresholds:\n",
        "                # Split data based on the threshold\n",
        "                left_indices = X[:, feature_index] <= threshold\n",
        "                right_indices = X[:, feature_index] > threshold\n",
        "                left_y = y[left_indices]\n",
        "                right_y = y[right_indices]\n",
        "\n",
        "                if len(left_y) == 0 or len(right_y) == 0:\n",
        "                    continue\n",
        "                \n",
        "                # Calculate information gain for this split\n",
        "                split_info_gain = self.compute_information_gain(y, left_y, right_y)\n",
        "\n",
        "                # Update best split if this one is better\n",
        "                if split_info_gain > best_split['info_gain']:\n",
        "                    best_split['info_gain'] = split_info_gain\n",
        "                    best_split['feature_index'] = feature_index\n",
        "                    best_split['threshold'] = threshold\n",
        "                    best_split['left'] = left_indices\n",
        "                    best_split['right'] = right_indices\n",
        "\n",
        "        return best_split\n",
        "\n",
        "    def compute_output(self, y):\n",
        "        \"\"\"Compute the majority class for a leaf node.\"\"\"\n",
        "        unique_classes, frequency = np.unique(y, return_counts=True)\n",
        "        majority_class = unique_classes[np.argmax(frequency)]  # Most frequent class\n",
        "        # majority_count = frequency.max()\n",
        "        # print(f\"\\nMajority Class: {majority_class} (Count: {majority_count})\")\n",
        "        return int(majority_class)\n",
        "\n",
        "    def compute_entropy(self, y):\n",
        "        \"\"\"Calculate the entropy of a set of labels.\"\"\"\n",
        "        unique_classes, frequencies = np.unique(y, return_counts=True)\n",
        "        n_classes = len(y)\n",
        "        entropy = 0\n",
        "        for frequency in frequencies:\n",
        "            probability = frequency / n_classes\n",
        "            entropy -= probability * log2(probability) if probability > 0 else 0\n",
        "        return entropy\n",
        "\n",
        "    def compute_information_gain(self, y, left_y, right_y):\n",
        "        \"\"\"Calculate information gain from a split.\"\"\"\n",
        "        m = len(y)\n",
        "        left_m = len(left_y)\n",
        "        right_m = len(right_y)\n",
        "\n",
        "        # Entropy before and after the split\n",
        "        parent_entropy = self.compute_entropy(y)\n",
        "        left_entropy = self.compute_entropy(left_y) if left_m > 0 else 0\n",
        "        right_entropy = self.compute_entropy(right_y) if right_m > 0 else 0\n",
        "\n",
        "        # Weighted average of child entropies\n",
        "        weighted_entropy = (left_m / m) * left_entropy + (right_m / m) * right_entropy\n",
        "        information_gain = parent_entropy - weighted_entropy\n",
        "        return information_gain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iGkG3DNeHYv"
      },
      "source": [
        "## DecisionTreeClassifier Class\n",
        "\n",
        "The `DecisionTreeClassifier` class implements a basic decision tree classifier. It recursively splits the feature space based on information gain, building a binary tree structure to classify data points. This implementation supports training, prediction, and visualization of the tree structure.\n",
        "\n",
        "### Parameters\n",
        "- **max_depth** (*int, optional*): Maximum depth of the tree. Defaults to 5. Controls overfitting by limiting tree growth.\n",
        "- **min_samples_split** (*int, optional*): Minimum number of samples required to split a node. Defaults to 2. Prevents splits on small datasets.\n",
        "\n",
        "### Methods\n",
        "- **`fit(X, y)`**: Trains the decision tree using feature matrix `X` and target vector `y`. Builds the tree starting from the root.\n",
        "- **`predict(X)`**: Predicts class labels for each sample in `X`. Requires the model to be trained first.\n",
        "- **`make_prediction(x, node)`**: Recursively traverses the tree to predict the class for a single sample `x`.\n",
        "- **`print_tree()`**: Prints the tree structure, showing split conditions and predictions.\n",
        "- **`build_tree(X, y, depth)`**: Recursively constructs the tree by finding the best splits.\n",
        "- **`get_best_split(X, y)`**: Identifies the feature and threshold that maximize information gain.\n",
        "- **`compute_output(y)`**: Determines the majority class for a leaf node.\n",
        "- **`compute_entropy(y)`**: Calculates the entropy of a set of labels.\n",
        "- **`compute_information_gain(y, left_y, right_y)`**: Computes the information gain for a split.\n",
        "\n",
        "### Usage\n",
        "This class is designed for classification tasks. It assumes numerical features and uses entropy and information gain to determine splits. The tree stops growing when it reaches `max_depth`, the data is pure (all labels are the same), or the number of samples is less than `min_samples_split`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training DecisionTree Classifier on Heart Failure Detection Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loading dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  MaxHR  \\\n",
            "0   40   M           ATA        140          289          0     Normal    172   \n",
            "1   49   F           NAP        160          180          0     Normal    156   \n",
            "2   37   M           ATA        130          283          0         ST     98   \n",
            "3   48   F           ASY        138          214          0     Normal    108   \n",
            "4   54   M           NAP        150          195          0     Normal    122   \n",
            "\n",
            "  ExerciseAngina  Oldpeak ST_Slope  HeartDisease  \n",
            "0              N      0.0       Up             0  \n",
            "1              N      1.0     Flat             1  \n",
            "2              N      0.0       Up             0  \n",
            "3              Y      1.5     Flat             1  \n",
            "4              N      0.0       Up             0  \n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>RestingBP</th>\n",
              "      <th>Cholesterol</th>\n",
              "      <th>FastingBS</th>\n",
              "      <th>MaxHR</th>\n",
              "      <th>Oldpeak</th>\n",
              "      <th>HeartDisease</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>918.000000</td>\n",
              "      <td>918.000000</td>\n",
              "      <td>918.000000</td>\n",
              "      <td>918.000000</td>\n",
              "      <td>918.000000</td>\n",
              "      <td>918.000000</td>\n",
              "      <td>918.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>53.510893</td>\n",
              "      <td>132.396514</td>\n",
              "      <td>198.799564</td>\n",
              "      <td>0.233115</td>\n",
              "      <td>136.809368</td>\n",
              "      <td>0.887364</td>\n",
              "      <td>0.553377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>9.432617</td>\n",
              "      <td>18.514154</td>\n",
              "      <td>109.384145</td>\n",
              "      <td>0.423046</td>\n",
              "      <td>25.460334</td>\n",
              "      <td>1.066570</td>\n",
              "      <td>0.497414</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>28.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>-2.600000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>47.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>173.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>54.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>223.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>138.000000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>60.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>267.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>156.000000</td>\n",
              "      <td>1.500000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>77.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>603.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>202.000000</td>\n",
              "      <td>6.200000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Age   RestingBP  Cholesterol   FastingBS       MaxHR  \\\n",
              "count  918.000000  918.000000   918.000000  918.000000  918.000000   \n",
              "mean    53.510893  132.396514   198.799564    0.233115  136.809368   \n",
              "std      9.432617   18.514154   109.384145    0.423046   25.460334   \n",
              "min     28.000000    0.000000     0.000000    0.000000   60.000000   \n",
              "25%     47.000000  120.000000   173.250000    0.000000  120.000000   \n",
              "50%     54.000000  130.000000   223.000000    0.000000  138.000000   \n",
              "75%     60.000000  140.000000   267.000000    0.000000  156.000000   \n",
              "max     77.000000  200.000000   603.000000    1.000000  202.000000   \n",
              "\n",
              "          Oldpeak  HeartDisease  \n",
              "count  918.000000    918.000000  \n",
              "mean     0.887364      0.553377  \n",
              "std      1.066570      0.497414  \n",
              "min     -2.600000      0.000000  \n",
              "25%      0.000000      0.000000  \n",
              "50%      0.600000      1.000000  \n",
              "75%      1.500000      1.000000  \n",
              "max      6.200000      1.000000  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "heart_df = pd.read_csv('heart.csv')\n",
        "heart_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Categorical Features Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "categorical_features = ['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope']\n",
        "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
        "encoded_features = encoder.fit_transform(heart_df[categorical_features])\n",
        "encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(categorical_features))\n",
        "modified_df = pd.concat([heart_df.drop(categorical_features, axis=1), encoded_df], axis=1)\n",
        "\n",
        "modified_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Splitting dataset into training, validation and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(642, 15)\n",
            "(92, 15)\n",
            "(184, 15)\n"
          ]
        }
      ],
      "source": [
        "X = modified_df.drop('HeartDisease', axis=1)\n",
        "y = modified_df['HeartDisease']\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.125, random_state=42)\n",
        "\n",
        "# Convert to NumPy arrays\n",
        "X_train = X_train.to_numpy()\n",
        "X_val = X_val.to_numpy()\n",
        "X_test = X_test.to_numpy()\n",
        "y_train = y_train.to_numpy()\n",
        "y_val = y_val.to_numpy()\n",
        "y_test = y_test.to_numpy()\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_val.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training DecisionTreeClassifier Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X[14] <= 0.0 -> True:\n",
            " X[12] <= 0.0 -> True:\n",
            "  X[6] <= 0.0 -> True:\n",
            "   X[2] <= 0.0 -> True:\n",
            "    Predict: 1\n",
            "   X[2] > 0.0 -> False:\n",
            "    X[2] <= 220.0 -> True:\n",
            "     Predict: 0\n",
            "    X[2] > 220.0 -> False:\n",
            "     X[1] <= 146.0 -> True:\n",
            "      X[0] <= 53.0 -> True:\n",
            "       Predict: 0\n",
            "      X[0] > 53.0 -> False:\n",
            "       Predict: 0\n",
            "     X[1] > 146.0 -> False:\n",
            "      Predict: 1\n",
            "  X[6] > 0.0 -> False:\n",
            "   X[5] <= 0.0 -> True:\n",
            "    X[7] <= 0.0 -> True:\n",
            "     X[4] <= 97.0 -> True:\n",
            "      Predict: 1\n",
            "     X[4] > 97.0 -> False:\n",
            "      Predict: 1\n",
            "    X[7] > 0.0 -> False:\n",
            "     Predict: 0\n",
            "   X[5] > 0.0 -> False:\n",
            "    X[5] <= 1.2 -> True:\n",
            "     X[2] <= 293.0 -> True:\n",
            "      X[2] <= 273.0 -> True:\n",
            "       Predict: 0\n",
            "      X[2] > 273.0 -> False:\n",
            "       Predict: 1\n",
            "     X[2] > 293.0 -> False:\n",
            "      Predict: 0\n",
            "    X[5] > 1.2 -> False:\n",
            "     X[1] <= 120.0 -> True:\n",
            "      Predict: 1\n",
            "     X[1] > 120.0 -> False:\n",
            "      X[4] <= 155.0 -> True:\n",
            "       Predict: 1\n",
            "      X[4] > 155.0 -> False:\n",
            "       Predict: 0\n",
            " X[12] > 0.0 -> False:\n",
            "  X[2] <= 170.0 -> True:\n",
            "   X[1] <= 178.0 -> True:\n",
            "    Predict: 1\n",
            "   X[1] > 178.0 -> False:\n",
            "    Predict: 0\n",
            "  X[2] > 170.0 -> False:\n",
            "   X[5] <= 2.0 -> True:\n",
            "    X[2] <= 177.0 -> True:\n",
            "     Predict: 0\n",
            "    X[2] > 177.0 -> False:\n",
            "     X[1] <= 110.0 -> True:\n",
            "      X[0] <= 47.0 -> True:\n",
            "       Predict: 1\n",
            "      X[0] > 47.0 -> False:\n",
            "       Predict: 0\n",
            "     X[1] > 110.0 -> False:\n",
            "      X[5] <= 1.0 -> True:\n",
            "       Predict: 1\n",
            "      X[5] > 1.0 -> False:\n",
            "       Predict: 1\n",
            "   X[5] > 2.0 -> False:\n",
            "    X[11] <= 0.0 -> True:\n",
            "     Predict: 1\n",
            "    X[11] > 0.0 -> False:\n",
            "     Predict: 1\n",
            "X[14] > 0.0 -> False:\n",
            " X[2] <= 0.0 -> True:\n",
            "  X[3] <= 0.0 -> True:\n",
            "   X[4] <= 98.0 -> True:\n",
            "    Predict: 1\n",
            "   X[4] > 98.0 -> False:\n",
            "    X[4] <= 154.0 -> True:\n",
            "     X[0] <= 43.0 -> True:\n",
            "      Predict: 1\n",
            "     X[0] > 43.0 -> False:\n",
            "      X[0] <= 66.0 -> True:\n",
            "       Predict: 0\n",
            "      X[0] > 66.0 -> False:\n",
            "       Predict: 1\n",
            "    X[4] > 154.0 -> False:\n",
            "     Predict: 1\n",
            "  X[3] > 0.0 -> False:\n",
            "   Predict: 1\n",
            " X[2] > 0.0 -> False:\n",
            "  X[0] <= 56.0 -> True:\n",
            "   X[7] <= 0.0 -> True:\n",
            "    X[8] <= 0.0 -> True:\n",
            "     X[4] <= 142.0 -> True:\n",
            "      Predict: 0\n",
            "     X[4] > 142.0 -> False:\n",
            "      X[4] <= 173.0 -> True:\n",
            "       Predict: 0\n",
            "      X[4] > 173.0 -> False:\n",
            "       Predict: 0\n",
            "    X[8] > 0.0 -> False:\n",
            "     X[2] <= 149.0 -> True:\n",
            "      Predict: 0\n",
            "     X[2] > 149.0 -> False:\n",
            "      Predict: 0\n",
            "   X[7] > 0.0 -> False:\n",
            "    Predict: 0\n",
            "  X[0] > 56.0 -> False:\n",
            "   X[5] <= 1.8 -> True:\n",
            "    X[8] <= 0.0 -> True:\n",
            "     X[2] <= 303.0 -> True:\n",
            "      X[6] <= 0.0 -> True:\n",
            "       Predict: 0\n",
            "      X[6] > 0.0 -> False:\n",
            "       Predict: 0\n",
            "     X[2] > 303.0 -> False:\n",
            "      Predict: 1\n",
            "    X[8] > 0.0 -> False:\n",
            "     X[2] <= 318.0 -> True:\n",
            "      Predict: 0\n",
            "     X[2] > 318.0 -> False:\n",
            "      Predict: 0\n",
            "   X[5] > 1.8 -> False:\n",
            "    Predict: 1\n"
          ]
        }
      ],
      "source": [
        "decision_tree_classifier = DecisionTreeClassifier()\n",
        "decision_tree_classifier.fit(X_train, y_train)\n",
        "decision_tree_classifier.print_tree()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tuning Hyperparameters (max depth & minmum samples in split)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Manipulating classification error on different combinations of max depth and minimum samples in split using validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(cm):\n",
        "    \"\"\"Plot the confusion matrix.\"\"\"\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(cm, cmap='Blues', interpolation='nearest')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.colorbar(label='Count')\n",
        "    plt.xticks([0, 1], ['Predicted 0', 'Predicted 1'])\n",
        "    plt.yticks([0, 1], ['True 0', 'True 1'])\n",
        "    for i in range(2):\n",
        "        for j in range(2):\n",
        "            plt.text(j, i, cm[i, j], ha='center', va='center', color='black')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Misclassification Error (Depth=2, MinSamplesSplit=2): 0.09782608695652174\n",
            "Misclassification Error (Depth=2, MinSamplesSplit=5): 0.09782608695652174\n",
            "Misclassification Error (Depth=2, MinSamplesSplit=10): 0.09782608695652174\n",
            "Misclassification Error (Depth=2, MinSamplesSplit=15): 0.09782608695652174\n",
            "Misclassification Error (Depth=2, MinSamplesSplit=20): 0.09782608695652174\n",
            "Misclassification Error (Depth=2, MinSamplesSplit=25): 0.09782608695652174\n",
            "Misclassification Error (Depth=2, MinSamplesSplit=30): 0.09782608695652174\n",
            "\n",
            "Misclassification Error (Depth=3, MinSamplesSplit=2): 0.10869565217391304\n",
            "Misclassification Error (Depth=3, MinSamplesSplit=5): 0.10869565217391304\n",
            "Misclassification Error (Depth=3, MinSamplesSplit=10): 0.10869565217391304\n",
            "Misclassification Error (Depth=3, MinSamplesSplit=15): 0.10869565217391304\n",
            "Misclassification Error (Depth=3, MinSamplesSplit=20): 0.10869565217391304\n",
            "Misclassification Error (Depth=3, MinSamplesSplit=25): 0.10869565217391304\n",
            "Misclassification Error (Depth=3, MinSamplesSplit=30): 0.10869565217391304\n",
            "\n",
            "Misclassification Error (Depth=5, MinSamplesSplit=2): 0.13043478260869565\n",
            "Misclassification Error (Depth=5, MinSamplesSplit=5): 0.13043478260869565\n",
            "Misclassification Error (Depth=5, MinSamplesSplit=10): 0.13043478260869565\n",
            "Misclassification Error (Depth=5, MinSamplesSplit=15): 0.13043478260869565\n",
            "Misclassification Error (Depth=5, MinSamplesSplit=20): 0.13043478260869565\n",
            "Misclassification Error (Depth=5, MinSamplesSplit=25): 0.13043478260869565\n",
            "Misclassification Error (Depth=5, MinSamplesSplit=30): 0.13043478260869565\n",
            "\n",
            "Misclassification Error (Depth=7, MinSamplesSplit=2): 0.16304347826086957\n",
            "Misclassification Error (Depth=7, MinSamplesSplit=5): 0.16304347826086957\n",
            "Misclassification Error (Depth=7, MinSamplesSplit=10): 0.15217391304347827\n",
            "Misclassification Error (Depth=7, MinSamplesSplit=15): 0.16304347826086957\n",
            "Misclassification Error (Depth=7, MinSamplesSplit=20): 0.16304347826086957\n",
            "Misclassification Error (Depth=7, MinSamplesSplit=25): 0.16304347826086957\n",
            "Misclassification Error (Depth=7, MinSamplesSplit=30): 0.16304347826086957\n",
            "\n",
            "Misclassification Error (Depth=9, MinSamplesSplit=2): 0.15217391304347827\n",
            "Misclassification Error (Depth=9, MinSamplesSplit=5): 0.15217391304347827\n",
            "Misclassification Error (Depth=9, MinSamplesSplit=10): 0.14130434782608695\n",
            "Misclassification Error (Depth=9, MinSamplesSplit=15): 0.15217391304347827\n",
            "Misclassification Error (Depth=9, MinSamplesSplit=20): 0.15217391304347827\n",
            "Misclassification Error (Depth=9, MinSamplesSplit=25): 0.16304347826086957\n",
            "Misclassification Error (Depth=9, MinSamplesSplit=30): 0.16304347826086957\n",
            "\n",
            "Misclassification Error (Depth=11, MinSamplesSplit=2): 0.15217391304347827\n",
            "Misclassification Error (Depth=11, MinSamplesSplit=5): 0.16304347826086957\n",
            "Misclassification Error (Depth=11, MinSamplesSplit=10): 0.15217391304347827\n",
            "Misclassification Error (Depth=11, MinSamplesSplit=15): 0.15217391304347827\n",
            "Misclassification Error (Depth=11, MinSamplesSplit=20): 0.15217391304347827\n",
            "Misclassification Error (Depth=11, MinSamplesSplit=25): 0.16304347826086957\n",
            "Misclassification Error (Depth=11, MinSamplesSplit=30): 0.16304347826086957\n",
            "\n",
            "Misclassification Error (Depth=13, MinSamplesSplit=2): 0.15217391304347827\n",
            "Misclassification Error (Depth=13, MinSamplesSplit=5): 0.16304347826086957\n",
            "Misclassification Error (Depth=13, MinSamplesSplit=10): 0.15217391304347827\n",
            "Misclassification Error (Depth=13, MinSamplesSplit=15): 0.15217391304347827\n",
            "Misclassification Error (Depth=13, MinSamplesSplit=20): 0.15217391304347827\n",
            "Misclassification Error (Depth=13, MinSamplesSplit=25): 0.16304347826086957\n",
            "Misclassification Error (Depth=13, MinSamplesSplit=30): 0.16304347826086957\n",
            "\n",
            "Misclassification Error (Depth=15, MinSamplesSplit=2): 0.15217391304347827\n",
            "Misclassification Error (Depth=15, MinSamplesSplit=5): 0.16304347826086957\n",
            "Misclassification Error (Depth=15, MinSamplesSplit=10): 0.15217391304347827\n",
            "Misclassification Error (Depth=15, MinSamplesSplit=15): 0.15217391304347827\n",
            "Misclassification Error (Depth=15, MinSamplesSplit=20): 0.15217391304347827\n",
            "Misclassification Error (Depth=15, MinSamplesSplit=25): 0.16304347826086957\n",
            "Misclassification Error (Depth=15, MinSamplesSplit=30): 0.16304347826086957\n",
            "\n"
          ]
        }
      ],
      "source": [
        "max_depths = [2, 3, 5, 7, 9, 11, 13, 15]\n",
        "min_samples_splits = [2, 5, 10, 15, 20, 25, 30]\n",
        "misclassification_errors = np.zeros((len(max_depths), len(min_samples_splits)))\n",
        "\n",
        "for i, max_depth in enumerate(max_depths):\n",
        "    for j, min_samples_split in enumerate(min_samples_splits):\n",
        "        decision_tree_classifier = DecisionTreeClassifier(max_depth=max_depth, min_samples_split=min_samples_split)\n",
        "        decision_tree_classifier.fit(X_train, y_train)\n",
        "        y_pred = decision_tree_classifier.predict(X_val)\n",
        "        # cm = confusion_matrix(y_val, y_pred)\n",
        "        # plot_confusion_matrix(cm)\n",
        "        misclassification_errors[i, j] = np.mean(y_pred != y_val)\n",
        "        print(f\"Misclassification Error (Depth={max_depth}, MinSamplesSplit={min_samples_split}): {misclassification_errors[i, j]}\")\n",
        "    print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Getting the best hyperparameters values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Max Depth: 2\n",
            "Best Min Samples Split: 2\n",
            "Misclassification Error: 0.15760869565217392\n",
            "Accuracy: 0.842391304347826\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi0AAAHiCAYAAAAkv/yOAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAASNBJREFUeJzt3X18zfX/x/HnGdvZ2nbONhe7qJm5iCkK+Wpy3RjfFF9+X1+VDF2HXISoXE21KBcpob5yVbpQqKh8mRChIkIsRPaNTaVthl3Yzu+P7Hw7bbQd53y2Y4+72+d22/lcvM/rc5zWy+t98THZbDabAAAAKjiv8g4AAACgNEhaAACARyBpAQAAHoGkBQAAeASSFgAA4BFIWgAAgEcgaQEAAB6BpAUAAHiEquUdAAAAlUVOTo7y8vLc0raPj498fX3d0nZFQdICAIABcnJy5BdYTTp/1i3th4WF6ciRI1d04kLSAgCAAfLy8qTzZ2VulCBV8XFt4wV5SvtukfLy8khaAACAi1T1lcnFSYvNVDmGqFaOuwQAAB6PSgsAAEYySTKZXN9mJUDSAgCAkUxev2+ubrMSqBx3CQAAPB6VFgAAjGQyuaF7qHL0D1FpAQAAHoFKCwAARmJMi9Mqx10CAACPR6UFAAAjMabFaVRaAACAR6DSAgCAodwwpqWS1CBIWgAAMBLdQ06rHKkZAADweFRaAAAwElOenVY57hIAAHg8khYAAIxUNKbF1VsZnT59WsOGDVNUVJT8/PzUqlUrffXVV/bjNptN48ePV3h4uPz8/BQXF6eDBw+6+MMoG5IWAAAqofvuu09r167VkiVLtGfPHnXu3FlxcXH66aefJElTp07VrFmzNHfuXG3fvl3+/v6Kj49XTk5OucVsstlstnJ7dwAAKomsrCxZrVaZW46SqarZpW3bzucqd/vzyszMlMVi+cvzz507p8DAQH3wwQe67bbb7PubN2+url27avLkyYqIiNBjjz2mkSNHSpIyMzMVGhqqhQsXqk+fPi6Nv7SotAAAUMmcP39eBQUF8vX1ddjv5+enzZs368iRI0pLS1NcXJz9mNVqVcuWLbV169ZyiPh3zB4CAMBIblynJSsry2G32WyW2Vy8qhMYGKjY2FhNnjxZMTExCg0N1VtvvaWtW7eqXr16SktLkySFhoY6XBcaGmo/Vh6otAAV2MGDB9W5c2dZrVaZTCatXLnSpe0fPXpUJpNJCxcudGm7nqx9+/Zq3759eYeBK1nRlGdXb5IiIyNltVrtW1JS0kXDWLJkiWw2m66++mqZzWbNmjVLd955p7y8Km5qUHEjAyqIw4cP68EHH1SdOnXk6+sri8WiW265RS+++KLOnTvn1vdOSEjQnj179Mwzz2jJkiW66aab3Pp+Rurfv79MJpMsFkuJn+PBgwdlMplkMpn0wgsvlLn948ePa+LEidq1a5eLIgYqvtTUVGVmZtq3sWPHXvTcunXrauPGjcrOzlZqaqq+/PJL5efnq06dOgoLC5MkpaenO1yTnp5uP1Ye6B4CLmH16tX65z//KbPZrH79+un6669XXl6eNm/erFGjRmnfvn169dVX3fLe586d09atW/Xkk09q8ODBbnmPqKgonTt3Tt7e3m5p/69UrVpVZ8+e1UcffaTevXs7HHvzzTfl6+vr9EyF48ePa9KkSapdu7ZuvPHGUl/3n//8x6n3A0rNZHLD4nK/dw9ZLJZSDcT9I39/f/n7++u3337TmjVrNHXqVEVHRyssLEzJycn2/36ysrK0fft2Pfzww66NvQxIWoCLOHLkiPr06aOoqCitX79e4eHh9mODBg3SoUOHtHr1are9/88//yxJCgoKctt7mEymYgPxjGQ2m3XLLbforbfeKpa0LF26VLfddpvef/99Q2I5e/asrrrqKvn4+BjyfkB5W7NmjWw2mxo0aKBDhw5p1KhRatiwoQYMGCCTyaRhw4bp6aefVv369RUdHa1x48YpIiJCPXr0KLeY6R4CLmLq1KnKzs7W/PnzHRKWIvXq1dPQoUPtr8+fP6/Jkyerbt26MpvNql27tp544gnl5uY6XFe7dm1169ZNmzdv1t/+9jf5+vqqTp06Wrx4sf2ciRMnKioqSpI0atQomUwm1a5dW7rQrVL08x9NnDhRpj8N7lu7dq1at26toKAgBQQEqEGDBnriiSfsxy82pmX9+vVq06aN/P39FRQUpO7du2v//v0lvt+hQ4fUv39/BQUFyWq1asCAATp79mypP+e77rpLn3zyiTIyMuz7vvrqKx08eFB33XVXsfNPnTqlkSNHqnHjxgoICJDFYlHXrl21e/du+zkbNmxQixYtJMn+C/iP99m+fXtdf/312rFjh9q2baurrrrK/rn8eUxLQkKCfH19i91/fHy8goODdfz48VLfKyBJ8jK5ZyujzMxMDRo0SA0bNlS/fv3UunVrrVmzxl55HT16tIYMGaIHHnhALVq0UHZ2tj799NNy/YcOSQtwER999JHq1KmjVq1aler8++67T+PHj1ezZs00Y8YMtWvXTklJSSWuZ3Do0CH93//9nzp16qRp06YpODhY/fv31759+yRJPXv21IwZMyRJd955p5YsWaKZM2eWKf59+/apW7duys3NVWJioqZNm6Y77rhDW7ZsueR169atU3x8vE6ePKmJEydqxIgR+uKLL3TLLbfo6NGjxc7v3bu3Tp8+raSkJPXu3VsLFy7UpEmTSh1nz549ZTKZtHz5cvu+pUuXqmHDhmrWrFmx83/44QetXLlS3bp10/Tp0zVq1Cjt2bNH7dq1sycQMTExSkxMlCQ98MADWrJkiZYsWaK2bdva2/n111/VtWtX3XjjjZo5c6Y6dOhQYnwvvviiatSooYSEBBUUFEiS5s2bp//85z966aWXFBERUep7BSqS3r176/Dhw8rNzdWJEyf08ssvy2q12o+bTCYlJiYqLS1NOTk5Wrduna699tpyjZnuIaAEWVlZ+umnn9S9e/dSnb97924tWrRI9913n1577TVJ0iOPPKKaNWvqhRde0GeffebwP8WUlBRt2rRJbdq0kS788oiMjNSCBQv0wgsvqEmTJrJYLBo+fLiaNWumvn37lvke1q5dq7y8PH3yySeqXr16qa8bNWqUQkJCtHXrVoWEhEiSevTooaZNm2rChAlatGiRw/lNmzbV/Pnz7a9//fVXzZ8/X1OmTCnV+wUGBqpbt25aunSpBg4cqMLCQr399tsX7Tdv3Lixvv/+e4cZDvfcc48aNmyo+fPna9y4cQoNDVXXrl01fvx4xcbGlvj5paWlae7cuXrwwQcvGV9QUJDmz5+v+Ph4Pffcc7rrrrs0cuRI9ejRw6m/F4AHJjqvctwlUEZFax0EBgaW6vyPP/5YkjRixAiH/Y899ph0YUDvHzVq1MiesEhSjRo11KBBA/3www+XHXuRorEwH3zwgQoLC0t1zYkTJ7Rr1y7179/fnrBIUpMmTdSpUyf7ff7RQw895PC6TZs2+vXXX4utF3Epd911lzZs2KC0tDStX79eaWlpJXYN6cI4mKKEpaCgQL/++qu962vnzp2lfk+z2awBAwaU6tzOnTvrwQcfVGJionr27ClfX1/Nmzev1O8FwDVIWoASFI2+P336dKnO//HHH+Xl5aV69eo57A8LC1NQUJB+/PFHh/21atUq1kZwcLB+++23y4r7j/71r3/plltu0X333afQ0FD16dNH77777iUTmKI4GzRoUOxYTEyMfvnlF505c8Zh/5/vJTg4WJLKdC9///vfFRgYqHfeeUdvvvmmWrRoUeyzLFJYWKgZM2aofv36MpvNql69umrUqKFvv/1WmZmZpX7Pq6++ukyDbl944QWFhIRo165dmjVrlmrWrFnqawEHFeSBiZ6IpAUogcViUUREhPbu3Vum6/48EPZiqlSpUuL+0jwK7GLvUTTeooifn582bdqkdevW6Z577tG3336rf/3rX+rUqVOxcy/H5dxLEbPZrJ49e2rRokVasWLFRasskvTss89qxIgRatu2rd544w2tWbNGa9eu1XXXXVfqipIufD5l8c033+jkyZOSpD179pTpWsCBGxeXu9JVjrsEnNCtWzcdPny4VM/ZiIqKUmFhYbHHtqenpysjI8M+E8gVgoODHWbaFPlzNUeSvLy8dOutt2r69On67rvv9Mwzz2j9+vX67LPPLnofujDm5s8OHDig6tWry9/f3yX38Wd33XWXvvnmG50+ffqSD2N777331KFDB82fP199+vSxP5n2z59JaRPI0jhz5owGDBigRo0a6YEHHtDUqVP11Vdfuax9AKVD0gJcxOjRo+Xv76/77ruv2KqQurBS7osvvihd6N6QVGyGz/Tp0yXJ4Smql6tu3brKzMzUt99+a9934sQJrVixwuG8U6dOFbu2aJGoP0/DLhIeHq4bb7xRixYtckgC9u7dq//85z/2+3SHDh06aPLkyXr55ZcvueJmlSpVilVxli1bpp9++slhX1FyVVKCV1aPP/64jh07pkWLFmn69OmqXbu2EhISLvo5ApdE95DTmD0EXETdunW1dOlS/etf/1JMTIzDirhffPGFli1bpv79+0uSbrjhBiUkJOjVV19VRkaG2rVrpy+//FKLFi1Sjx49Ljqd1hl9+vTR448/rn/84x969NFHdfbsWc2ZM0fXXnutw0DUxMREbdq0SbfddpuioqJ08uRJvfLKK7rmmmvUunXri7b//PPPq2vXroqNjdW9996rc+fO6aWXXpLVatXEiRNddh9/5uXlpaeeeuovz+vWrZsSExM1YMAAtWrVSnv27NGbb76pOnXqOJxXt25dBQUFae7cuQoMDJS/v79atmyp6OjoMsW1fv16vfLKK5owYYJ9CvaCBQvUvn17jRs3TlOnTi3jnQJwFkkLcAl33HGHvv32Wz3//PP64IMPNGfOHJnNZjVp0kTTpk3T/fffbz/33//+t+rUqaOFCxdqxYoVCgsL09ixYzVhwgSXxlStWjWtWLFCI0aM0OjRoxUdHa2kpCQdPHjQIWm54447dPToUb3++uv65ZdfVL16dbVr106TJk1yWIvhz+Li4vTpp59qwoQJGj9+vLy9vdWuXTtNmTKlzP/Dd4cnnnhCZ86c0dKlS/XOO++oWbNmWr16tcaMGeNwnre3txYtWqSxY8fqoYce0vnz57VgwYIy3cPp06c1cOBANW3aVE8++aR9f5s2bTR06FBNmzZNPXv21M033+zSe8QVjinPTjPZyjJaDgAAOCUrK0tWq1XmDokyVXXtqrK28znK/Wy8MjMzy/zsIU9CpQUAACO5YwxKJRnTUjnqSQAAwONRaQEAwEiMaXFa5bhLAADg8ai0AABgJMa0OI2kBQAAQ7lj2f3K0XFC0uIChYWFOn78uAIDA126dDgAwFg2m02nT59WRESE/WniqDhIWlzg+PHjioyMLO8wAAAukpqaqmuuucY9jdM95DSSFhcIDAyUJN363Eeq6uueh8kBFcGrfW4s7xAAtzp9OkvX169t/72OioWkxQWKuoSq+vrL2y+gvMMB3OZKXmkT+CO3dvWbTG6Y8lw5Ki102AEAAI9ApQUAACOxuJzTKsddAgAAj0elBQAAIzF7yGkkLQAAGInuIadVjrsEAAAej0oLAABGonvIaVRaAACAR6DSAgCAkRjT4rTKcZcAAMDjUWkBAMBIjGlxGpUWAADgEai0AABgIJPJ5PoHMlaSSgtJCwAABiJpcR7dQwAAwCNQaQEAwEimC5ur26wEqLQAAACPQKUFAAADMabFeVRaAACAR6DSAgCAgai0OI9KCwAA8AhUWgAAMBCVFueRtAAAYCCSFufRPQQAADwClRYAAIzE4nJOo9ICAAA8ApUWAAAMxJgW51FpAQCgkikoKNC4ceMUHR0tPz8/1a1bV5MnT5bNZrOfY7PZNH78eIWHh8vPz09xcXE6ePBgucZN0gIAgIFMpv9VW1y3lS2GKVOmaM6cOXr55Ze1f/9+TZkyRVOnTtVLL71kP2fq1KmaNWuW5s6dq+3bt8vf31/x8fHKyclx/YdSSnQPAQBQyXzxxRfq3r27brvtNklS7dq19dZbb+nLL7+ULlRZZs6cqaeeekrdu3eXJC1evFihoaFauXKl+vTpUy5xU2kBAMBAJrm6ymKSqYzTh1q1aqXk5GR9//33kqTdu3dr8+bN6tq1qyTpyJEjSktLU1xcnP0aq9Wqli1bauvWrS7+REqPSgsAAAZy50DcrKwsh91ms1lms7nY6WPGjFFWVpYaNmyoKlWqqKCgQM8884zuvvtuSVJaWpokKTQ01OG60NBQ+7HyQKUFAIArRGRkpKxWq31LSkoq8bx3331Xb775ppYuXaqdO3dq0aJFeuGFF7Ro0SLDYy4LKi0AABjJjYvLpaamymKx2HeXVGWRpFGjRmnMmDH2sSmNGzfWjz/+qKSkJCUkJCgsLEySlJ6ervDwcPt16enpuvHGG10cfOlRaQEA4AphsVgctoslLWfPnpWXl2MKUKVKFRUWFkqSoqOjFRYWpuTkZPvxrKwsbd++XbGxsW6+i4uj0gIAgJHcMKbFVsb2br/9dj3zzDOqVauWrrvuOn3zzTeaPn26Bg4ceCFEk4YNG6ann35a9evXV3R0tMaNG6eIiAj16NHDpbGXBUkLAACVzEsvvaRx48bpkUce0cmTJxUREaEHH3xQ48ePt58zevRonTlzRg888IAyMjLUunVrffrpp/L19S23uE22Py5/B6dkZWXJarUqfuZ6efsFlHc4gNssuadZeYcAuFVWVpaiwkKUmZnpMDbEVW1brVaF3PW6vHyucmnbhXlndWrpQLfEXZEwpgUAAHgEuocAADCQO9Zpcfm6LxUUSQsAAEZy45TnKx3dQwAAwCNQaQEAwEB0DzmPSgsAAPAIVFoAADAQlRbnUWkBAAAegUoLAAAGotLiPCotAADAI1BpAQDAQFRanEfSAgCAkVhczml0DwEAAI9ApQUAAAPRPeQ8Ki0AAMAjUGkBAMBAVFqcR6UFAAB4BCotAAAYiEqL86i0AAAAj0ClBQAAI7FOi9NIWgAAMBDdQ86jewgAAHgEKi0AABiISovzqLQAAACPQKUFAAADmeSGSkslGYlLpQUAAHgEKi0AABiIMS3Oo9ICAAA8ApUWAACMxOJyTqPSAgAAPAKVFgAADMSYFueRtAAAYCCSFufRPQQAADwClRYAAAxkMv2+ubrNyoBKCwAA8AhUWgAAMNDvlRZXj2lxaXMVFpUWAADgEai0AABgJDeMaWFxOQAAgAqESgsAAAZinRbnkbQAAGAgpjw7j+4hAADgEai0AABgIC8vk7y8XFsasbm4vYqKSgsAAPAIVFoAADAQY1qcR6UFAAB4BJIWVGjnfjupb+aP15oRcfp4cBttnHSnMo5+Zz9+Yudn2jZziNaMiNOqB/+mzNTvyzVewBlbNm9Sn17dFVMnUsFXVdXqDz8odk7Kgf268/96qFZYiK6ublHH1jcrNfVYucSLy1M05dnVW1nUrl27xDYGDRokScrJydGgQYNUrVo1BQQEqFevXkpPT3fTJ1J65Za0/NWHP3HiRMNisdlsGj9+vMLDw+Xn56e4uDgdPHjQsPdHyfLOZOmL5++XqUpV/W3Ii2o/8W01+udQeftb7OcU5J1TSL0bFNNzcLnGClyOs2fO6PrGTfT8jJdKPH7kh8PqGtdO9Rs00KpPk7X5y280csyT8jX7Gh4rrgxfffWVTpw4Yd/Wrl0rSfrnP/8pSRo+fLg++ugjLVu2TBs3btTx48fVs2fPco66HMe0nDhxwv7zO++8o/HjxyslJcW+LyAgwP6zzWZTQUGBqlZ1T7hTp07VrFmztGjRIkVHR2vcuHGKj4/Xd999J19ffimUl8NrFssvuKZu7D/evu+q6lc7nHPNzX+XJJ395bjh8QGu0im+qzrFd73o8ckTx6lTfFclPjPFvi+6Tl2DooOrVYQxLTVq1HB4/dxzz6lu3bpq166dMjMzNX/+fC1dulQdO3aUJC1YsEAxMTHatm2bbr75ZleGXiblVmkJCwuzb1arVSaTyf76wIEDCgwM1CeffKLmzZvLbDZr8+bN6t+/v3r06OHQzrBhw9S+fXv768LCQiUlJSk6Olp+fn664YYb9N577100DpvNppkzZ+qpp55S9+7d1aRJEy1evFjHjx/XypUr3foZ4NLSv/1c1qgY7Zg3Rv8ZGa9NT/fVj5/zd4LKpbCwUGs//Vj16tVXrzu6qn5UuOLaxpbYhQTPUBG6h/4oLy9Pb7zxhgYOHCiTyaQdO3YoPz9fcXFx9nMaNmyoWrVqaevWrS76FJxToce0jBkzRs8995z279+vJk2alOqapKQkLV68WHPnztW+ffs0fPhw9e3bVxs3bizx/CNHjigtLc3hL8dqtaply5bl/pdT2Z39+Sf9uHG5/GvWUstHZymqbS/te2eaUreuKu/QAMP8fPKksrOzNXPaVN3aKV7LP/xEt93RQ/fc+X/a8nnJv9dQeWVlZTlsubm5f3nNypUrlZGRof79+0uS0tLS5OPjo6CgIIfzQkNDlZaW5rbYS6NCT3lOTExUp06dSn1+bm6unn32Wa1bt06xsbGSpDp16mjz5s2aN2+e2rVrV+yaor+A0NBQh/2X+svJzc11+CJkZWWVOkaUns1WqKCoGDX8xyOSJGutBjp9/LB+3LhckbHdyjs8wBCFhYWSpK7d7tAjQ4ZJkhrfcKO+3LZVr//7Vd3SpvjvNVRs7nz2UGRkpMP+CRMm/OUY0fnz56tr166KiIhwaUzuUKGTlptuuqlM5x86dEhnz54tlujk5eWpadOmLosrKSlJkyZNcll7KJmvtboCwqMd9gWE19aJbz4rt5gAo1WrXl1Vq1ZVw4YxDvuvbdhQ277YUm5xoWJKTU2VxfK/yQpms/mS5//4449at26dli9fbt8XFhamvLw8ZWRkOFRb0tPTFRYW5qbIS6dCJy3+/v4Or728vGSz2Rz25efn23/Ozs6WJK1evVpXX+04YPNif3FFfwHp6ekKDw+3709PT9eNN95Y4jVjx47ViBEj7K+zsrKKZbe4fMF1m+hM+o8O+86kH9NVIeX7Hw1gJB8fHzVtfpMOHnSczn/44EFF1ooqt7jgPHcOxLVYLA5Jy19ZsGCBatasqdtuu82+r3nz5vL29lZycrJ69eolSUpJSdGxY8fsvRjlpUInLX9Wo0YN7d2712Hfrl275O3tLUlq1KiRzGazjh07VmJXUEmio6MVFham5ORke5KSlZWl7du36+GHHy7xGrPZ/JfZKy5fnbi7tGXKvTr48QJF3BSnjKP7dOzzlWrc9wn7OXlnMnXuVLpyMn6WJJ1J+z3JMVtC5GutXm6xA2WRnZ2tI4cP2V//+OMR7dm9S0EhIYqMrKVHh43UwH53qtUtbdSmXXut+88affrxKn20Jrlc44ZnKyws1IIFC5SQkOAwO9dqteree+/ViBEjFBISIovFoiFDhig2NrZcZw7J05KWjh076vnnn9fixYsVGxurN954Q3v37rV3/QQGBmrkyJEaPny4CgsL1bp1a2VmZmrLli2yWCxKSEgo1qbJZNKwYcP09NNPq379+vYpzxEREcVmKsFYQbUb6aaHp+rAild0cPV8XVU9Qo16j9A1LbvYz0nf/bl2L0q0v9757yclSfW73acGtz9QLnEDZbVr59e6vcv/JgM8+fhISdKdffvplVdfV7fuPTR91iua8cIUjRk5TPXqN9DipcsU26p1OUYNZ5nkhjEtKnt769at07FjxzRw4MBix2bMmCEvLy/16tVLubm5io+P1yuvvOKiaJ3nUUlLfHy8xo0bp9GjRysnJ0cDBw5Uv379tGfPHvs5kydPVo0aNZSUlKQffvhBQUFBatasmZ544omLtjt69GidOXNGDzzwgDIyMtS6dWt9+umnrNFSAYQ2aaPQJm0uejyyVTdFtmJQLjxb67bt9dvZ85c8p2/CAPVNGGBYTLjyde7cudiQiyK+vr6aPXu2Zs+ebXhcl2KyXSxilFpWVpasVqviZ66Xt19AKa4APNOSe5qVdwiAW2VlZSkqLESZmZllGhtS2ratVquajP1QVXz9S3FF6RXknNG3SXe4Je6KxKMqLQAAeDp3Tnm+0lXoxeUAAACKUGkBAMBAFeHZQ56KSgsAAPAIVFoAADAQY1qcR6UFAAB4BCotAAAYiDEtzqPSAgAAPAKVFgAADMSYFueRtAAAYCQ3dA858eghj0T3EAAA8AhUWgAAMBDdQ86j0gIAADwClRYAAAzElGfnUWkBAAAegUoLAAAGYkyL86i0AAAAj0ClBQAAAzGmxXkkLQAAGIjuIefRPQQAADwClRYAAAxEpcV5VFoAAIBHoNICAICBGIjrPCotAADAI1BpAQDAQIxpcR6VFgAA4BGotAAAYCDGtDiPpAUAAAPRPeQ8uocAAIBHoNICAICBTG7ozqkcdRYqLQAAwENQaQEAwEBeJpO8XFxqcXV7FRWVFgAA4BGotAAAYCCmPDuPSgsAAPAIVFoAADAQ67Q4j6QFAAADeZl+31zdZmVA9xAAAPAIVFoAADCSyQ3dOVRaAAAAKg4qLQAAGIgpz86j0gIAADwClRYAAAxkuvDH1W1WBlRaAACAR6DSAgCAgVinxXlUWgAAMFDRiriu3srqp59+Ut++fVWtWjX5+fmpcePG+vrrr+3HbTabxo8fr/DwcPn5+SkuLk4HDx508adRNiQtAABUMr/99ptuueUWeXt765NPPtF3332nadOmKTg42H7O1KlTNWvWLM2dO1fbt2+Xv7+/4uPjlZOTU25x0z0EAICBKsKU5ylTpigyMlILFiyw74uOjrb/bLPZNHPmTD311FPq3r27JGnx4sUKDQ3VypUr1adPH9cFXwZUWgAAqGQ+/PBD3XTTTfrnP/+pmjVrqmnTpnrttdfsx48cOaK0tDTFxcXZ91mtVrVs2VJbt24tp6hJWgAAMJSXyeSWTZKysrIcttzc3BJj+OGHHzRnzhzVr19fa9as0cMPP6xHH31UixYtkiSlpaVJkkJDQx2uCw0NtR8rDyQtAABcISIjI2W1Wu1bUlJSiecVFhaqWbNmevbZZ9W0aVM98MADuv/++zV37lzDYy4LxrQAAGAgd45pSU1NlcVise83m80lnh8eHq5GjRo57IuJidH7778vSQoLC5MkpaenKzw83H5Oenq6brzxRtcGXwZUWgAAuEJYLBaH7WJJyy233KKUlBSHfd9//72ioqKkC4Nyw8LClJycbD+elZWl7du3KzY21s13cXFUWgAAMJCz66r8VZtlMXz4cLVq1UrPPvusevfurS+//FKvvvqqXn31VXt7w4YN09NPP6369esrOjpa48aNU0REhHr06OHS2MuCpAUAgEqmRYsWWrFihcaOHavExERFR0dr5syZuvvuu+3njB49WmfOnNEDDzygjIwMtW7dWp9++ql8fX3LLW6SFgAADFQR1mmRpG7duqlbt26XaNOkxMREJSYmXl5wLkTSAgCAgf44RdmVbVYGDMQFAAAegUoLAAAGMl3YXN1mZUClBQAAeAQqLQAAGKgiTHn2VFRaAACAR6DSAgCAgbxMv2+ubrMyoNICAAA8ApUWAAAMxJgW55G0AABgsEqSY7gc3UMAAMAjUGkBAMBAdA85j0oLAADwCCQtAAAYqGjKs6u3iqZOnTr69ddfi+3PyMhQnTp1nGqTpAUAALjc0aNHVVBQUGx/bm6ufvrpJ6faZEwLAAAGutLHtHz44Yf2n9esWSOr1Wp/XVBQoOTkZNWuXduptklaAACAy/To0UO6kEglJCQ4HPP29lbt2rU1bdo0p9omaQEAwECmC5ur26woCgsLJUnR0dH66quvVL16dZe17dSYls8//1x9+/ZVbGysvV9qyZIl2rx5s8sCAwDgSuRlMrllq2iOHDni0oRFzlRa3n//fd1zzz26++679c033yg3N1eSlJmZqWeffVYff/yxSwMEAACeKTk5WcnJyTp58qS9AlPk9ddfL3N7Za60PP3005o7d65ee+01eXt72/ffcsst2rlzZ5kDAACgMjGZ3LNVNJMmTVLnzp2VnJysX375Rb/99pvD5owyV1pSUlLUtm3bYvutVqsyMjKcCgIAAFxZ5s6dq4ULF+qee+5xWZtlrrSEhYXp0KFDxfZv3rzZ6cViAACoLIqmPLt6q2jy8vLUqlUrl7ZZ5qTl/vvv19ChQ7V9+3aZTCYdP35cb775pkaOHKmHH37YpcEBAADPdN9992np0qUubbPM3UNjxoxRYWGhbr31Vp09e1Zt27aV2WzWyJEjNWTIEJcGBwDAlcYdY1AqYKFFOTk5evXVV7Vu3To1adLEYRysJE2fPr3MbZY5aTGZTHryySc1atQoHTp0SNnZ2WrUqJECAgLK/OYAAODK9O233+rGG2+UJO3du9fhmLPdWU4vLufj46NGjRo5ezkAAJWSO9ZVqYjrtHz22Wcub7PMSUuHDh0umSGtX7/+cmMCAOCKVVm6h9yhzElLUamnSH5+vnbt2qW9e/cWe8YAAAConNxR5Chz0jJjxowS90+cOFHZ2dllDgAAgMrkSn/KcxF3FDlc9sDEvn376m9/+5teeOEFVzXpcRbf01wWi6W8wwDcJrjF4PIOAXArW0FeeYdwxXBHkcOpByaWZOvWrfL19XVVcwAAXJG83LR5ir59+zr13CE5U2np2bOnw2ubzaYTJ07o66+/1rhx45wKAgAAVA6XU+Qoc9JitVodXnt5ealBgwZKTExU586dnQoCAIDKorKMaXFHkaNMSUtBQYEGDBigxo0bKzg42Kk3BAAAVz53FDnKlLRUqVJFnTt31v79+0laAABwgskkeVWCdVoWLFjg8jbL3D10/fXX64cfflB0dLTLgwEA4Ern5YakxdXtudKOHTu0f/9+SdJ1112npk2bOt1WmZOWp59+WiNHjtTkyZPVvHlz+fv7Oxxnyi8AADh58qT69OmjDRs2KCgoSJKUkZGhDh066O2331aNGjXK3GapZ0klJibqzJkz+vvf/67du3frjjvu0DXXXKPg4GAFBwcrKCiILiMAAP5C0UBcV28VzZAhQ3T69Gnt27dPp06d0qlTp7R3715lZWXp0UcfdarNUldaJk2apIceesgtD0ACAABXlk8//VTr1q1TTEyMfV+jRo00e/Zs9w/EtdlskqR27do59UYAAKDyjGkpLCyUt7d3sf3e3t4qLCx0qs0yLaJXEctPAACg4unYsaOGDh2q48eP2/f99NNPGj58uG699Van2izTQNxrr732LxOXU6dOORUIAACVgcnk+inKFbGm8PLLL+uOO+5Q7dq1FRkZKUlKTU3V9ddfrzfeeMOpNsuUtEyaNKnYYjEAAAB/FhkZqZ07d2rdunU6cOCAJCkmJkZxcXFOt1mmpKVPnz6qWbOm028GAEBl52UyycvFpRFXt3c51q9fr8GDB2vbtm2yWCzq1KmTOnXqJEnKzMzUddddp7lz56pNmzZlbrvUY1oYzwIAwOW70p/yPHPmTN1///0lrttmtVr14IMPavr06U61Xer7LJo9BAAAPNvEiROLrfPSsGFD+/GcnBwNGjRI1apVU0BAgHr16qX09PRStb1792516dLlosc7d+6sHTt2OBV3qbuHnJ2eBAAA/qeiDMS97rrrtG7dOvvrqlX/lxIMHz5cq1ev1rJly2S1WjV48GD17NlTW7Zs+ct209PTS5zq/Mf3+fnnn8sesDPL+AMAAM9XtWpVhYWFFdufmZmp+fPna+nSperYsaN04eGHMTEx2rZtm26++eZLtnv11Vdr7969qlevXonHv/32W4WHhzsVc0XqBgMA4IrnJZN9MK7LNpW91HLw4EFFRESoTp06uvvuu3Xs2DHpwgMO8/PzHWb5NGzYULVq1dLWrVv/st2///3vGjdunHJycoodO3funCZMmKBu3bqVOV5RaQEA4MqRlZXl8NpsNstsNhc7r2XLllq4cKEaNGigEydOaNKkSWrTpo327t2rtLQ0+fj42B9yWCQ0NFRpaWl/GcNTTz2l5cuX69prr9XgwYPVoEEDSdKBAwc0e/ZsFRQU6Mknn3Tq/khaAAAwkDvHtBQt4lZkwoQJmjhxYrHzu3btav+5SZMmatmypaKiovTuu+/Kz8/vsmIJDQ3VF198oYcfflhjx461T+QxmUyKj4/X7NmzFRoa6lTbJC0AAFwhUlNTHaYal1RlKUlQUJCuvfZaHTp0SJ06dVJeXp4yMjIcqi3p6ekljoEpSVRUlD7++GP99ttvOnTokGw2m+rXr6/g4GAn7up/GNMCAICBih6Y6OpNkiwWi8NW2qQlOztbhw8fVnh4uJo3by5vb28lJyfbj6ekpOjYsWOKjY0t070GBwerRYsW+tvf/nbZCYuotAAAYCyTyfUr2Ja1uZEjR+r2229XVFSUjh8/rgkTJqhKlSq68847ZbVade+992rEiBEKCQmRxWLRkCFDFBsb+5czh9yNpAUAgErmv//9r+688079+uuvqlGjhlq3bq1t27apRo0akqQZM2bIy8tLvXr1Um5uruLj4/XKK6+Ud9gkLQAAGKkiLC739ttvX/K4r6+vZs+erdmzZ19eYC7GmBYAAOARqLQAAGCgPw6cdWWblQGVFgAA4BGotAAAYCDThT+ubrMyoNICAAA8ApUWAAAMxJgW55G0AABgIJIW59E9BAAAPAKVFgAADGQymWRy+TL+laPUQqUFAAB4BCotAAAYiDEtzqPSAgAAPAKVFgAADFQRHpjoqai0AAAAj0ClBQAAA3mZTPJycWnE1e1VVFRaAACAR6DSAgCAgZg95DySFgAAjOSGgbiV5CHPdA8BAADPQKUFAAADeckkLxeXRlzdXkVFpQUAAHgEKi0AABiIxeWcR6UFAAB4BCotAAAYiCnPzqPSAgAAPAKVFgAADMQy/s4jaQEAwEAMxHUe3UMAAMAjUGkBAMBAXnJD9xCLywEAAFQcVFoAADAQY1qcR6UFAAB4BCotAAAYyMsNFYPKUoGoLPcJAAA8HJUWAAAMZDKZZHLxIBRXt1dRkbQAAGAg04XN1W1WBnQPAQAAj0ClBQAAA/HsIedRaQEAAB6BSgsAAAarHHUR16PSAgAAPAKVFgAADMQy/s6j0gIAADwClRYAAAzE4nLOI2kBAMBAPHvIeZXlPgEAgIej0gIAgIHoHnIelRYAACq55557TiaTScOGDbPvy8nJ0aBBg1StWjUFBASoV69eSk9PL9c4SVoAADCQyU2bs7766ivNmzdPTZo0cdg/fPhwffTRR1q2bJk2btyo48ePq2fPnpd9/5eDpAUAgEoqOztbd999t1577TUFBwfb92dmZmr+/PmaPn26OnbsqObNm2vBggX64osvtG3btnKLl6QFAAADFY1pcfUmSVlZWQ5bbm7uJWMZNGiQbrvtNsXFxTns37Fjh/Lz8x32N2zYULVq1dLWrVvd9Mn8NZIWAACuEJGRkbJarfYtKSnpoue+/fbb2rlzZ4nnpKWlycfHR0FBQQ77Q0NDlZaW5pbYS4PZQwAAGMid67SkpqbKYrHY95vN5hLPT01N1dChQ7V27Vr5+vq6OBr3IWkBAMBA7pzybLFYHJKWi9mxY4dOnjypZs2a2fcVFBRo06ZNevnll7VmzRrl5eUpIyPDodqSnp6usLAwl8ZeFiQtAABUMrfeeqv27NnjsG/AgAFq2LChHn/8cUVGRsrb21vJycnq1auXJCklJUXHjh1TbGxsOUVN0gIAgKEud4ryxdosi8DAQF1//fUO+/z9/VWtWjX7/nvvvVcjRoxQSEiILBaLhgwZotjYWN18880ujLxsSFoAAEAxM2bMkJeXl3r16qXc3FzFx8frlVdeKdeYSFoAADCQyfT75uo2L9eGDRscXvv6+mr27NmaPXv25TfuIkx5BgAAHoFKCwAABvKSSV4uHtXi6vYqKiotAADAI5C0oELb/Pkm9epxu6JrRcjP26QPP1jpcPzpxIm64fqGqmb1V3iNYP09Pk5fbt9ebvECzrAV5Cn/v58rZ98i5eyeq9zv31fh2ZKfppufukE5u2br/MndhscJ1yga0+LqrTIgaUGFdubMGTVucoNmzip5IFi9+tdqxosv6+tv9ih5w2ZFRdXW7X/vrJ9//tnwWAFn5ad+psLsVPlEdZJPwz7yCoxU3qEPZcvLdjivIOMHFZ5Jk7z9yy1WXD6Tm/5UBuWWtPzVg58mTpxoWCzLly9X586dVa1aNZlMJu3atcuw98alxXfpqomJT6t7j3+UeLzPnXep461xiq5TR42uu05TXpiurKws7d3zreGxAs6wFZ5XYcZhVQ1vJa+ACHmZg+Qd/jeZzFad/3Xv/87Ly1b+T5vkHdWJf2+i0iq3gbgnTpyw//zOO+9o/PjxSklJse8LCAiw/2yz2VRQUKCqVd0T7pkzZ9S6dWv17t1b999/v1veA+6Xl5en+f9+VVarVY2b3FDe4QClYyuUZJO8qjju96qqwuzff0/abDblH1unqjWbysuvWvnECZepqFOePUG5pethYWH2zWq1ymQy2V8fOHBAgYGB+uSTT9S8eXOZzWZt3rxZ/fv3V48ePRzaGTZsmNq3b29/XVhYqKSkJEVHR8vPz0833HCD3nvvvUvGcs8992j8+PHFHs0Nz/Dx6lWqHhSgoABfvfTiDK36ZK2qV69e3mEBpWKq4iPTVWE6n/a1bPlnZLMVquBUimxn0qTzZyVJBSd3SiYvVanepLzDBcpVhZ7yPGbMGL3wwguqU6eOgoODS3VNUlKS3njjDc2dO1f169fXpk2b1LdvX9WoUUPt2rVzSVy5ubnKzc21v87KynJJu3BOu/YdtP3rXfrll1+0YP5r6ntXb23asl01a9Ys79CAUvGOilP+sfXK3bfw9xEPV9WQV3B92c7+rMKzJ3X+590yN/iXyx+yh/JhcsOU58oypqVCJy2JiYnq1KlTqc/Pzc3Vs88+q3Xr1tkf6FSnTh1t3rxZ8+bNc1nSkpSUpEmTJrmkLVw+f39/1a1XT3Xr1VPLm2/W9TH1tWjBfI16fGx5hwaUipfZKnP9f8hWkC8V5snk7a+8o2tkMlt+7yI6f065+xb94Qqbzh/fovM/75bvdf3KMXLAWBU6abnpppvKdP6hQ4d09uzZYolOXl6emjZt6rK4xo4dqxEjRthfZ2VlKTIy0mXt4/IUFhY6VMIAT2Gq4i1V8ZbtfI4Ks46pakQrVQmqK6/AaxzOy/vhI1UJbqAqIQ3LLVY4jzEtzqvQSYu/v+O0Pi8vL9lsNod9+fn59p+zs3+fHrh69WpdffXVDueZzWaXxWU2m13aHi4uOztbhw8dsr8+euSIdu/apeCQEFWrVk1Tkp7Rbd3uUFh4uH795RfNmzNbx3/6ST17/bNc4wbKoiDrmCSbTOZg2fIydf6nLTL5BqtKtYYymarIVNX3T1d4yVT1Knn5lq7bHLhSVOik5c9q1KihvXv3OuzbtWuXvL29JUmNGjWS2WzWsWPHXNYVhPK1c8fXio/rYH/9+KjfK1x970nQS6/MVUrKAb2xZJF+/eUXhVSrpptuaqF1n32uRtddV45RA2VUkKvzJ7bJlp8tVfFVlaC6qhreUiZTlVJcDE9DpcV5HpW0dOzYUc8//7wWL16s2NhYvfHGG9q7d6+96ycwMFAjR47U8OHDVVhYqNatWyszM1NbtmyRxWJRQkJCie2eOnVKx44d0/HjxyXJPvW6aDYTyk/bdu11Lt920ePvLFtuaDyAO1QJrq8qwfVLfT7jWDybOxaDqywDcT1qhaL4+HiNGzdOo0ePVosWLXT69Gn16+f4H+/kyZM1btw4JSUlKSYmRl26dNHq1asVHR190XY//PBDNW3aVLfddpskqU+fPmratKnmzp3r9nsCAAClY7L9eZAIyiwrK0tWq1Xpv2bKYrGUdziA2wS3GFzeIQBuZSvIU+6e15SZ6frf50X/r/jgqx/kHxDo0rbPZJ9W9xZ13BJ3ReJRlRYAAFB5edSYFgAAPB1jWpxHpQUAAHgEKi0AABiIKc/Oo9ICAAA8ApUWAAAMZHLDGJRKUmghaQEAwEhept83V7dZGdA9BAAAPAKVFgAADMSUZ+dRaQEAAB6BSgsAAAZiyrPzqLQAAACPQKUFAAADmdwwRbmSFFqotAAAAM9ApQUAAAN5ySQvFw9C8aoktRYqLQAAwCNQaQEAwECMaXEeSQsAAEYia3Ea3UMAAMAjUGkBAMBALOPvPCotAADAI1BpAQDASG5Yxr+SFFqotAAAAM9ApQUAAAMxech5VFoAAIBHoNICAICRKLU4jaQFAAADMeXZeXQPAQAAj0ClBQAAA5ncMOXZ5VOoKygqLQAAwCOQtAAAYCCTm7aymDNnjpo0aSKLxSKLxaLY2Fh98skn9uM5OTkaNGiQqlWrpoCAAPXq1Uvp6eku/yzKiqQFAIBK5pprrtFzzz2nHTt26Ouvv1bHjh3VvXt37du3T5I0fPhwffTRR1q2bJk2btyo48ePq2fPnuUdNmNaAAAwVAWY8nz77bc7vH7mmWc0Z84cbdu2Tddcc43mz5+vpUuXqmPHjpKkBQsWKCYmRtu2bdPNN9/sysjLhEoLAABXiKysLIctNzf3L68pKCjQ22+/rTNnzig2NlY7duxQfn6+4uLi7Oc0bNhQtWrV0tatW918B5dG0gIAgIFMbvojSZGRkbJarfYtKSnponHs2bNHAQEBMpvNeuihh7RixQo1atRIaWlp8vHxUVBQkMP5oaGhSktLc/vncyl0DwEAYCB3TnlOTU2VxWKx7zebzRe9pkGDBtq1a5cyMzP13nvvKSEhQRs3bnRtYC5G0gIAwBWiaDZQafj4+KhevXqSpObNm+urr77Siy++qH/961/Ky8tTRkaGQ7UlPT1dYWFhbou9NOgeAgDAQBVhynNJCgsLlZubq+bNm8vb21vJycn2YykpKTp27JhiY2Nd8E7Oo9ICAEAlM3bsWHXt2lW1atXS6dOntXTpUm3YsEFr1qyR1WrVvffeqxEjRigkJEQWi0VDhgxRbGxsuc4cEkkLAAAGqwBTnk+ePKl+/frpxIkTslqtatKkidasWaNOnTpJkmbMmCEvLy/16tVLubm5io+P1yuvvOLioMuOpAUAgEpm/vz5lzzu6+ur2bNna/bs2YbFVBokLQAAGOiPU5Rd2WZlwEBcAADgEai0AABgIHeu03KlI2kBAMBAFWAcrseiewgAAHgEKi0AABiJUovTqLQAAACPQKUFAAADMeXZeVRaAACAR6DSAgCAgZjy7DwqLQAAwCNQaQEAwEBMHnIeSQsAAEYia3Ea3UMAAMAjUGkBAMBATHl2HpUWAADgEai0AABgIKY8O49KCwAA8AhUWgAAMBCTh5xHpQUAAHgEKi0AABiJUovTSFoAADAQU56dR/cQAADwCFRaAAAwkhumPFeSQguVFgAA4BmotAAAYCDG4TqPSgsAAPAIVFoAADASpRanUWkBAAAegUoLAAAGYp0W55G0AABgIJ7y7Dy6hwAAgEeg0gIAgIEYh+s8Ki0AAMAjUGkBAMBIlFqcRqUFAAB4BCotAAAYiCnPzqPSAgAAPAKVFgAADGRyw7oqlaPOQtICAIChGIfrPLqHAACAR6DSAgCAgVjG33lUWgAAgEeg0gIAgKEY1eIskhYXsNlskqTTWVnlHQrgVraCvPIOAXCrou940e91VCwkLS5w+vRpSVK96MjyDgUA4AKnT5+W1Wp1S9uMaXEeSYsLREREKDU1VYGBgTJVlm9OOcvKylJkZKRSU1NlsVjKOxzALfieG89ms+n06dOKiIgo71DcKikpScuXL9eBAwfk5+enVq1aacqUKWrQoIH9nJycHD322GN6++23lZubq/j4eL3yyisKDQ0tt7hJWlzAy8tL11xzTXmHUSlZLBZ+meOKx/fcWO6qsBSpCCNaNm7cqEGDBqlFixY6f/68nnjiCXXu3Fnfffed/P39JUnDhw/X6tWrtWzZMlmtVg0ePFg9e/bUli1bXBx96ZG0AABgoIrQPfTpp586vF64cKFq1qypHTt2qG3btsrMzNT8+fO1dOlSdezYUZK0YMECxcTEaNu2bbr55ptdGX6pMeUZAIArRFZWlsOWm5tbqusyMzMlSSEhIZKkHTt2KD8/X3FxcfZzGjZsqFq1amnr1q1uiv6vkbTAI5nNZk2YMEFms7m8QwHchu/5lcnkpj+SFBkZKavVat+SkpL+Mp7CwkINGzZMt9xyi66//npJUlpamnx8fBQUFORwbmhoqNLS0tz0yfw1uofgkcxmsyZOnFjeYQBuxfccZfXnQdulSXgHDRqkvXv3avPmzW6O7vKRtAAAYCQ3jsQt66DtwYMHa9WqVdq0aZPDhJKwsDDl5eUpIyPDodqSnp6usLAw18ZeBnQPAQBQydhsNg0ePFgrVqzQ+vXrFR0d7XC8efPm8vb2VnJysn1fSkqKjh07ptjY2HKI+HdUWgAAMFBFmPI8aNAgLV26VB988IECAwPt41SsVqv8/PxktVp17733asSIEQoJCZHFYtGQIUMUGxtbbjOHRKUFFU3//v3Vo0cP++v27dtr2LBhhsexYcMGmUwmZWRkGP7euPLxPUd5mzNnjjIzM9W+fXuFh4fbt3feecd+zowZM9StWzf16tVLbdu2VVhYmJYvX16ucZO04C/1799fJpNJJpNJPj4+qlevnhITE3X+/Hm3v/fy5cs1efLkUp1r9C/gnJwcDRo0SNWqVVNAQIB69eql9PR0Q94brsf3vGSvvvqq2rdvL4vFQoLjIkXrtLh6KwubzVbi1r9/f/s5vr6+mj17tk6dOqUzZ85o+fLl5TqeRSQtKK0uXbroxIkTOnjwoB577DFNnDhRzz//fInn5uW57qF6ISEhCgwMdFl7rjR8+HB99NFHWrZsmTZu3Kjjx4+rZ8+e5R0WLgPf8+LOnj2rLl266IknnijvUACSFpSO2WxWWFiYoqKi9PDDDysuLk4ffvih9IdS9zPPPKOIiAj7sytSU1PVu3dvBQUFKSQkRN27d9fRo0ftbRYUFGjEiBEKCgpStWrVNHr06GJPVv1z2Tw3N1ePP/64IiMjZTabVa9ePc2fP19Hjx5Vhw4dJEnBwcEymUz2fzEUFhYqKSlJ0dHR8vPz0w033KD33nvP4X0+/vhjXXvttfLz81OHDh0c4ixJ0WqR06dPV8eOHdW8eXMtWLBAX3zxhbZt23bZnzfKB9/z4oYNG6YxY8aU6ziGK40712m50pG0wCl+fn4O/9JMTk5WSkqK1q5dq1WrVik/P1/x8fEKDAzU559/ri1btiggIEBdunSxXzdt2jQtXLhQr7/+ujZv3qxTp05pxYoVl3zffv366a233tKsWbO0f/9+zZs3TwEBAYqMjNT7778vXRjhfuLECb344ovShQeDLV68WHPnztW+ffs0fPhw9e3bVxs3bpQu/E+nZ8+euv3227Vr1y7dd999GjNmzCXjqKirRcK1Kvv3HG5ictNWGdiAv5CQkGDr3r27zWaz2QoLC21r1661mc1m28iRI+3HQ0NDbbm5ufZrlixZYmvQoIGtsLDQvi83N9fm5+dnW7Nmjc1ms9nCw8NtU6dOtR/Pz8+3XXPNNfb3stlstnbt2tmGDh1qs9lstpSUFJsk29q1a0uM87PPPrNJsv3222/2fTk5ObarrrrK9sUXXzice++999ruvPNOm81ms40dO9bWqFEjh+OPP/54sbb+6M0337T5+PgU29+iRQvb6NGjS7wGFRvf80sr6X1RNpmZmTZJtsM//Wo7eTrfpdvhn361SbJlZmaW9226FVOeUSqrVq1SQECA8vPzVVhYqLvuusthpc7GjRvLx8fH/nr37t06dOhQsX76nJwcHT58WJmZmTpx4oRatmxpP1a1alXddNNNxUrnRXbt2qUqVaqoXbt2pY770KFDOnv2rDp16uSwPy8vT02bNpUk7d+/3yEOSeW6DgHKD99zGKEiTHn2VCQtKJUOHTpozpw58vHxUUREhKpWdfzqFD3KvEh2draaN2+uN998s1hbNWrUcCoGPz+/Ml+TnZ0tSVq9erWuvvpqh2OX8zyXirpaJC4P33OgYiNpQan4+/urXr16pT6/WbNmeuedd1SzZs2LLikdHh6u7du3q23btpKk8+fPa8eOHWrWrFmJ5zdu3FiFhYXauHGjw1iSIkX/Ai4oKLDva9Sokcxms44dO3bRf7nGxMTYB1sW+avBtH9cLbJXr15SBVktEpeH7zmM4MwU5dK0WRkwEBducffdd6t69erq3r27Pv/8cx05ckQbNmzQo48+qv/+97+SpKFDh+q5557TypUrdeDAAT3yyCOXXAOidu3aSkhI0MCBA7Vy5Up7m++++64kKSoqSiaTSatWrdLPP/+s7OxsBQYGauTIkRo+fLgWLVqkw4cPa+fOnXrppZe0aNEiSdJDDz2kgwcPatSoUUpJSdHSpUu1cOHCS97fH1eL/Oyzz7Rjxw4NGDCg3FeLhLGu9O+5Ljztd9euXTp06JAkac+ePdq1a5dOnTrlok8RKIPyHlSDiu+PAxTLcvzEiRO2fv362apXr24zm822OnXq2O6//377QLH8/Hzb0KFDbRaLxRYUFGQbMWKErV+/fhcdoGiz2Wznzp2zDR8+3BYeHm7z8fGx1atXz/b666/bjycmJtrCwsJsJpPJlpCQYLNdGFQ5c+ZMW4MGDWze3t62GjVq2OLj420bN260X/fRRx/Z6tWrZzObzbY2bdrYXn/99b8cdHju3DnbI488YgsODrZdddVVtn/84x+2EydOlOmzRcXB97xkEyZMsEkqti1YsKBMny/+NxD3yPFTtl+zz7t0O3L8VKUYiGuyXWw0GAAAcJmsrCxZrVYdOX6qTE9iLm3b0REhyszMdHnbFQljWgAAMBBjWpzHmBYAAOARSFoAAIBHoHsIAAAD0T3kPCotAADAI1BpAQDAQO54KjNPeQYAAKhASFoAlKh///7q0aOH/XX79u01bNgww+PYsGGDTCbTJVeRBTxJ0ZgWV2+VAUkL4GH69+8vk8kkk8kkHx8f1atXT4mJiTp//rxb33f58uWaPHlyqc4l0QDgDoxpATxQly5dtGDBAuXm5urjjz/WoEGD5O3trbFjxzqcl5eXZ3/A3uUKCQlxSTtAZWe6sLm6zcqASgvggcxms8LCwhQVFaWHH35YcXFx+vDDD+1dOs8884wiIiLUoEEDSVJqaqp69+6toKAghYSEqHv37jp69Ki9vYKCAo0YMUJBQUGqVq2aRo8erT8/4ePP3UO5ubl6/PHHFRkZKbPZrHr16mn+/Pk6evSoOnToIEkKDg6WyWRS//79JUmFhYVKSkpSdHS0/Pz8dMMNN+i9995zeJ+PP/5Y1157rfz8/NShQweHOIErgslNWyVA0gJcAfz8/JSXlydJSk5OVkpKitauXatVq1YpPz9f8fHxCgwM1Oeff64tW7YoICBAXbp0sV8zbdo0LVy4UK+//ro2b96sU6dOacWKFZd8z379+umtt97SrFmztH//fs2bN08BAQGKjIzU+++/L0lKSUnRiRMn9OKLL0qSkpKStHjxYs2dO1f79u3T8OHD1bdvX23cuFG6kFz17NlTt99+u3bt2qX77rtPY8aMcfOnB8BT0D0EeDCbzabk5GStWbNGQ4YM0c8//yx/f3/9+9//tncLvfHGGyosLNS///1vmS6M1luwYIGCgoK0YcMGde7cWTNnztTYsWPVs2dPSdLcuXO1Zs2ai77v999/r3fffVdr165VXFycJKlOnTr240VdSTVr1lRQUJB0oTLz7LPPat26dYqNjbVfs3nzZs2bN0/t2rXTnDlzVLduXU2bNk2S1KBBA+3Zs0dTpkxx0ycIGI8pz84jaQE80KpVqxQQEKD8/HwVFhbqrrvu0sSJEzVo0CA1btzYYRzL7t27dejQIQUGBjq0kZOTo8OHDyszM1MnTpxQy5Yt7ceqVq2qm266qVgXUZFdu3apSpUqateuXaljPnTokM6ePatOnTo57M/Ly1PTpk0lSfv373eIQ5I9wQEAkhbAA3Xo0EFz5syRj4+PIiIiVLXq//5T9vf3dzg3OztbzZs315tvvlmsnRo1ajj1/n5+fmW+Jjs7W5K0evVqXX311Q7HzGazU3EAnohl/J1H0gJ4IH9/f9WrV69U5zZr1kzvvPOOatasKYvFUuI54eHh2r59u9q2bStJOn/+vHbs2KFmzZqVeH7jxo1VWFiojRs32ruH/qio0lNQUGDf16hRI5nNZh07duyiFZqYmBh9+OGHDvu2bdtWqvsEcOVjIC5whbv77rtVvXp1de/eXZ9//rmOHDmiDRs26NFHH9V///tfSdLQoUP13HPPaeXKlTpw4IAeeeSRS66xUrt2bSUkJGjgwIFauXKlvc13331XkhQVFSWTyaRVq1bp559/VnZ2tgIDAzVy5EgNHz5cixYt0uHDh7Vz50699NJLWrRokSTpoYce0sGDBzVq1CilpKRo6dKlWrhwoUGfFGAMJg85j6QFuMJdddVV2rRpk2rVqqWePXsqJiZG9957r3JycuyVl8cee0z33HOPEhISFBsbq8DAQP3jH/+4ZLtz5szR//3f/+mRRx5Rw4YNdf/99+vMmTOSpKuvvlqTJk3SmDFjFBoaqsGDB0uSJk+erHHjxikpKUkxMTHq0qWLVq9erejoaElSrVq19P7772vlypW64YYbNHfuXD377LNu/4wAeAaT7WIj7QAAgMtkZWXJarXqxC8ZF+2qvZy2w6sHKTMz0+VtVySMaQEAwEBMeXYe3UMAAMAjUGkBAMBATHl2HkkLAAAGysrK8og2KyKSFgAADODj46OwsDDVj450S/thYWEue6p7RcXsIQAADJKTk2N/UKmr+fj4yNfX1y1tVxQkLQAAwCMwewgAAHgEkhYAAOARSFoAAIBHIGkBAAAegaQFAAB4BJIWAADgEUhaAACAR/h/Lj6iO1E5nLwAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 600x600 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F1-Score: 0.866\n"
          ]
        }
      ],
      "source": [
        "best_idx = np.unravel_index(np.argmin(misclassification_errors, axis=None), misclassification_errors.shape)\n",
        "best_max_depth = max_depths[best_idx[0]]\n",
        "best_min_samples_split = min_samples_splits[best_idx[1]]\n",
        "print(f\"Best Max Depth: {best_max_depth}\")\n",
        "print(f\"Best Min Samples Split: {best_min_samples_split}\")\n",
        "\n",
        "decision_tree_classifier = DecisionTreeClassifier(max_depth=best_max_depth, min_samples_split=best_min_samples_split)\n",
        "decision_tree_classifier.fit(X_train, y_train)\n",
        "y_pred = decision_tree_classifier.predict(X_test)\n",
        "misclassification_error = np.mean(y_pred != y_test)\n",
        "print(f\"Misclassification Error: {misclassification_error}\")\n",
        "accuracy_score = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy_score}\")\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plot_confusion_matrix(cm)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "print(f\"F1-Score: {f1:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
